{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def cell_iterate(data):\n",
    "    for page in data[\"pageTables\"]:\n",
    "        for table_row in page[\"tables\"]:\n",
    "            with open('output.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                csvwriter = csv.writer(csvfile)\n",
    "                csvwriter.writerow(table_row)\n",
    "import json\n",
    "import os\n",
    "\n",
    "directory_path = r\"preprocessed_tables\"\n",
    "for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(directory_path, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        data = json.load(file)\n",
    "                        cell_iterate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "R\n",
      "I\n",
      "M\n",
      "E\n",
      "I\n",
      "R\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "E\n",
      "R\n",
      "G\n",
      "U\n",
      "N\n",
      "T\n",
      "A\n",
      "S\n",
      "\n",
      "S\n",
      "Ã\n",
      "O\n",
      "\n",
      "S\n",
      "O\n",
      "B\n",
      "R\n",
      "E\n",
      "\n",
      "Á\n",
      "L\n",
      "C\n",
      "O\n",
      "O\n",
      "L\n",
      "\n",
      "Q\n",
      "1\n",
      ".\n",
      "\n",
      "A\n",
      "L\n",
      "G\n",
      "U\n",
      "M\n",
      "A\n",
      "\n",
      "V\n",
      "E\n",
      "Z\n",
      "\n",
      "N\n",
      "A\n",
      "\n",
      "V\n",
      "I\n",
      "D\n",
      "A\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "i\n",
      "d\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "c\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "j\n",
      "a\n",
      ",\n",
      "\n",
      "v\n",
      "i\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "v\n",
      "o\n",
      "d\n",
      "k\n",
      "a\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "2\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "I\n",
      "D\n",
      "A\n",
      "D\n",
      "E\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "i\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "p\n",
      "e\n",
      "l\n",
      "a\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "i\n",
      "d\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      ")\n",
      "\n",
      "Q\n",
      "3\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "i\n",
      "d\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      ")\n",
      "\n",
      "Q\n",
      "4\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "ê\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "i\n",
      "d\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "U\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "M\n",
      "e\n",
      "n\n",
      "s\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "d\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "m\n",
      "e\n",
      "s\n",
      "e\n",
      "s\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      ")\n",
      "\n",
      "Q\n",
      "5\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "ê\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "u\n",
      "m\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "f\n",
      "i\n",
      "c\n",
      "o\n",
      "u\n",
      "\n",
      "b\n",
      "ê\n",
      "b\n",
      "e\n",
      "d\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "U\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "M\n",
      "e\n",
      "n\n",
      "s\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "d\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "m\n",
      "e\n",
      "s\n",
      "e\n",
      "s\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      ")\n",
      "\n",
      "\n",
      "Q\n",
      "6\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "e\n",
      "r\n",
      "\n",
      "t\n",
      "e\n",
      "m\n",
      "\n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "(\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "i\n",
      "s\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "s\n",
      "\n",
      "a\n",
      "m\n",
      "i\n",
      "g\n",
      "o\n",
      "s\n",
      ",\n",
      "\n",
      "n\n",
      "a\n",
      "\n",
      "e\n",
      "s\n",
      "c\n",
      "o\n",
      "l\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "n\n",
      "o\n",
      "\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "b\n",
      "a\n",
      "l\n",
      "h\n",
      "o\n",
      ")\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "t\n",
      "o\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "á\n",
      "l\n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      ")\n",
      "\n",
      "Q\n",
      "7\n",
      ".\n",
      "\n",
      "N\n",
      "o\n",
      "s\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "\n",
      ",\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "a\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "ê\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "\n",
      "d\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "u\n",
      "m\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "i\n",
      "d\n",
      "a\n",
      "s\n",
      "\n",
      "a\n",
      "l\n",
      "c\n",
      "o\n",
      "ó\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "s\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "1\n",
      "\n",
      "v\n",
      "ê\n",
      "s\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "m\n",
      "ê\n",
      "s\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "e\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "e\n",
      "\n",
      "2\n",
      "\n",
      "a\n",
      "\n",
      "4\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "m\n",
      "ê\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "e\n",
      "\n",
      "2\n",
      "\n",
      "a\n",
      "\n",
      "3\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "a\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "4\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "a\n",
      "n\n",
      "a\n",
      "\n",
      "Q\n",
      "8\n",
      ".\n",
      "\n",
      "N\n",
      "o\n",
      "s\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      ",\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "t\n",
      "a\n",
      "s\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "/\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "i\n",
      "d\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "l\n",
      "c\n",
      "o\n",
      "ó\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "u\n",
      "m\n",
      "\n",
      "d\n",
      "i\n",
      "a\n",
      "\n",
      "t\n",
      "í\n",
      "p\n",
      "i\n",
      "c\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "á\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "e\n",
      "n\n",
      "d\n",
      "o\n",
      "?\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "1\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "\n",
      "=\n",
      "\n",
      "1\n",
      "\n",
      "l\n",
      "a\n",
      "t\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "c\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "j\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "1\n",
      "\n",
      "t\n",
      "a\n",
      "ç\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "i\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "1\n",
      "\n",
      "m\n",
      "a\n",
      "r\n",
      "t\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "d\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "l\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "G\n",
      "a\n",
      "r\n",
      "r\n",
      "a\n",
      "f\n",
      "a\n",
      "\n",
      "c\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "j\n",
      "a\n",
      "\n",
      "=\n",
      "\n",
      "2\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "G\n",
      "a\n",
      "r\n",
      "r\n",
      "a\n",
      "f\n",
      "a\n",
      "\n",
      "v\n",
      "i\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "=\n",
      "\n",
      "8\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "G\n",
      "a\n",
      "r\n",
      "r\n",
      "a\n",
      "f\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "l\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "=\n",
      "\n",
      "3\n",
      "0\n",
      "\n",
      "a\n",
      "\n",
      "3\n",
      "5\n",
      "\n",
      "u\n",
      "n\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      "s\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "e\n",
      "\n",
      "1\n",
      "\n",
      "a\n",
      "\n",
      "2\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "e\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "\n",
      "4\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "e\n",
      "\n",
      "5\n",
      "\n",
      "a\n",
      "\n",
      "6\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "e\n",
      "\n",
      "7\n",
      "\n",
      "a\n",
      "\n",
      "9\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "1\n",
      "0\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "Q\n",
      "9\n",
      ".\n",
      "\n",
      "N\n",
      "o\n",
      "s\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      ",\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "a\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "ê\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      "\n",
      "6\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "d\n",
      "o\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "b\n",
      "e\n",
      "b\n",
      "i\n",
      "d\n",
      "a\n",
      "\n",
      "a\n",
      "l\n",
      "c\n",
      "o\n",
      "ó\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "\n",
      "m\n",
      "e\n",
      "s\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "c\n",
      "a\n",
      "s\n",
      "i\n",
      "ã\n",
      "o\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "M\n",
      "e\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "1\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "m\n",
      "ê\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "P\n",
      "e\n",
      "l\n",
      "o\n",
      "\n",
      "m\n",
      "e\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "1\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "m\n",
      "ê\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "P\n",
      "e\n",
      "l\n",
      "o\n",
      "\n",
      "m\n",
      "e\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "1\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "a\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "d\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "R\n",
      "Ó\n",
      "X\n",
      "I\n",
      "M\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "E\n",
      "R\n",
      "G\n",
      "U\n",
      "N\n",
      "T\n",
      "A\n",
      "S\n",
      "\n",
      "S\n",
      "Ã\n",
      "O\n",
      "\n",
      "S\n",
      "O\n",
      "B\n",
      "R\n",
      "E\n",
      "\n",
      "C\n",
      "I\n",
      "G\n",
      "A\n",
      "R\n",
      "R\n",
      "O\n",
      "\n",
      "E\n",
      "\n",
      "S\n",
      "U\n",
      "B\n",
      "S\n",
      "T\n",
      "Â\n",
      "N\n",
      "C\n",
      "I\n",
      "A\n",
      "S\n",
      "\n",
      "Q\n",
      "1\n",
      "0\n",
      ".\n",
      "\n",
      "A\n",
      "L\n",
      "G\n",
      "U\n",
      "M\n",
      "A\n",
      "\n",
      "V\n",
      "E\n",
      "Z\n",
      "\n",
      "N\n",
      "A\n",
      "\n",
      "V\n",
      "I\n",
      "D\n",
      "A\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "c\n",
      "i\n",
      "g\n",
      "a\n",
      "r\n",
      "r\n",
      "o\n",
      ",\n",
      "\n",
      "p\n",
      "a\n",
      "l\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "o\n",
      ",\n",
      "\n",
      "n\n",
      "a\n",
      "r\n",
      "g\n",
      "u\n",
      "i\n",
      "l\n",
      "é\n",
      ",\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "r\n",
      "u\n",
      "t\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "c\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "1\n",
      "1\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "I\n",
      "D\n",
      "A\n",
      "D\n",
      "E\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "i\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "e\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "u\n",
      "\n",
      "p\n",
      "e\n",
      "l\n",
      "a\n",
      "\n",
      "p\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "c\n",
      "i\n",
      "g\n",
      "a\n",
      "r\n",
      "r\n",
      "o\n",
      ")\n",
      "\n",
      "Q\n",
      "1\n",
      "2\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "c\n",
      "i\n",
      "g\n",
      "a\n",
      "r\n",
      "r\n",
      "o\n",
      ",\n",
      "\n",
      "p\n",
      "a\n",
      "l\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "o\n",
      ",\n",
      "\n",
      "\n",
      "n\n",
      "a\n",
      "r\n",
      "g\n",
      "u\n",
      "i\n",
      "l\n",
      "é\n",
      ",\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "r\n",
      "u\n",
      "t\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "c\n",
      "o\n",
      "u\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "c\n",
      "i\n",
      "g\n",
      "a\n",
      "r\n",
      "r\n",
      "o\n",
      ")\n",
      "\n",
      "Q\n",
      "1\n",
      "3\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "ê\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "c\n",
      "i\n",
      "g\n",
      "a\n",
      "r\n",
      "r\n",
      "o\n",
      ",\n",
      "\n",
      "p\n",
      "a\n",
      "l\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "o\n",
      ",\n",
      "\n",
      "n\n",
      "a\n",
      "r\n",
      "g\n",
      "u\n",
      "i\n",
      "l\n",
      "é\n",
      ",\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "r\n",
      "u\n",
      "t\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "c\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "U\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "M\n",
      "e\n",
      "n\n",
      "s\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "d\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "m\n",
      "e\n",
      "s\n",
      "e\n",
      "s\n",
      ")\n",
      "\n",
      "\n",
      "Q\n",
      "1\n",
      "4\n",
      ".\n",
      "\n",
      "O\n",
      "s\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "s\n",
      "\n",
      "A\n",
      "M\n",
      "I\n",
      "G\n",
      "O\n",
      "S\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "é\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "ó\n",
      "x\n",
      "i\n",
      "m\n",
      "o\n",
      "\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "\n",
      "s\n",
      "u\n",
      "a\n",
      "\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      "\n",
      "u\n",
      "s\n",
      "a\n",
      "m\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "s\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "s\n",
      "?\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "l\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "s\n",
      "a\n",
      "p\n",
      "a\n",
      "t\n",
      "e\n",
      "i\n",
      "r\n",
      "o\n",
      "\n",
      "\n",
      "S\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      ",\n",
      "\n",
      "t\n",
      "i\n",
      "n\n",
      "e\n",
      "r\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "l\n",
      "a\n",
      "n\n",
      "ç\n",
      "a\n",
      "-\n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "c\n",
      "a\n",
      "í\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "M\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "C\n",
      "r\n",
      "a\n",
      "c\n",
      "k\n",
      "\n",
      "\n",
      "E\n",
      "c\n",
      "s\n",
      "t\n",
      "a\n",
      "s\n",
      "y\n",
      "\n",
      "(\n",
      "M\n",
      "D\n",
      "M\n",
      "A\n",
      ",\n",
      "\n",
      "“\n",
      "b\n",
      "a\n",
      "l\n",
      "a\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "Á\n",
      "c\n",
      "i\n",
      "d\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "L\n",
      "S\n",
      "D\n",
      "\n",
      "(\n",
      "“\n",
      "d\n",
      "o\n",
      "c\n",
      "e\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      "i\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "a\n",
      "s\n",
      "p\n",
      "i\n",
      "r\n",
      "a\n",
      "d\n",
      "o\n",
      "/\n",
      "c\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "f\n",
      "u\n",
      "m\n",
      "a\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "E\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "ó\n",
      "i\n",
      "d\n",
      "e\n",
      "s\n",
      "\n",
      "(\n",
      "a\n",
      "n\n",
      "a\n",
      "b\n",
      "o\n",
      "l\n",
      "i\n",
      "z\n",
      "a\n",
      "n\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "“\n",
      "b\n",
      "o\n",
      "m\n",
      "b\n",
      "a\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "a\n",
      "r\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "\n",
      "“\n",
      "b\n",
      "a\n",
      "r\n",
      "a\n",
      "t\n",
      "o\n",
      "”\n",
      "?\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "o\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "(\n",
      "T\n",
      "r\n",
      "a\n",
      "m\n",
      "a\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      "T\n",
      "i\n",
      "l\n",
      "e\n",
      "x\n",
      ",\n",
      "\n",
      "O\n",
      "x\n",
      "y\n",
      "c\n",
      "o\n",
      "t\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "F\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "n\n",
      "i\n",
      "l\n",
      ",\n",
      "\n",
      "e\n",
      "t\n",
      "c\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "o\n",
      "r\n",
      "m\n",
      "i\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "L\n",
      "e\n",
      "x\n",
      "o\n",
      "t\n",
      "a\n",
      "n\n",
      ",\n",
      "\n",
      "V\n",
      "a\n",
      "l\n",
      "i\n",
      "u\n",
      "m\n",
      ",\n",
      "\n",
      "L\n",
      "o\n",
      "r\n",
      "a\n",
      "x\n",
      ",\n",
      "\n",
      "R\n",
      "i\n",
      "v\n",
      "o\n",
      "t\n",
      "r\n",
      "i\n",
      "l\n",
      ",\n",
      "\n",
      "e\n",
      "t\n",
      "c\n",
      ")\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "e\n",
      "m\n",
      "a\n",
      "g\n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "H\n",
      "i\n",
      "p\n",
      "o\n",
      "f\n",
      "a\n",
      "g\n",
      "i\n",
      "n\n",
      ",\n",
      "\n",
      "I\n",
      "n\n",
      "i\n",
      "b\n",
      "e\n",
      "x\n",
      ",\n",
      "\n",
      ",\n",
      "\n",
      "D\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "r\n",
      "e\n",
      "b\n",
      "i\n",
      "t\n",
      "e\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "O\n",
      "u\n",
      "t\n",
      "r\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "?\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q\n",
      "1\n",
      "5\n",
      ".\n",
      "\n",
      "E\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      ",\n",
      "\n",
      "A\n",
      "L\n",
      "G\n",
      "U\n",
      "M\n",
      "A\n",
      "\n",
      "V\n",
      "E\n",
      "Z\n",
      "\n",
      "N\n",
      "A\n",
      "\n",
      "V\n",
      "I\n",
      "D\n",
      "A\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "e\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "u\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "s\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "s\n",
      "?\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "l\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "s\n",
      "a\n",
      "p\n",
      "a\n",
      "t\n",
      "e\n",
      "i\n",
      "r\n",
      "o\n",
      "\n",
      "\n",
      "S\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      ",\n",
      "\n",
      "t\n",
      "i\n",
      "n\n",
      "e\n",
      "r\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "l\n",
      "a\n",
      "n\n",
      "ç\n",
      "a\n",
      "-\n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "c\n",
      "a\n",
      "í\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "M\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "C\n",
      "r\n",
      "a\n",
      "c\n",
      "k\n",
      "\n",
      "\n",
      "E\n",
      "c\n",
      "s\n",
      "t\n",
      "a\n",
      "s\n",
      "y\n",
      "\n",
      "(\n",
      "M\n",
      "D\n",
      "M\n",
      "A\n",
      ",\n",
      "\n",
      "“\n",
      "b\n",
      "a\n",
      "l\n",
      "a\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "Á\n",
      "c\n",
      "i\n",
      "d\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "L\n",
      "S\n",
      "D\n",
      "\n",
      "(\n",
      "“\n",
      "d\n",
      "o\n",
      "c\n",
      "e\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      "i\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "a\n",
      "s\n",
      "p\n",
      "i\n",
      "r\n",
      "a\n",
      "d\n",
      "o\n",
      "/\n",
      "c\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "f\n",
      "u\n",
      "m\n",
      "a\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "E\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "ó\n",
      "i\n",
      "d\n",
      "e\n",
      "s\n",
      "\n",
      "(\n",
      "a\n",
      "n\n",
      "a\n",
      "b\n",
      "o\n",
      "l\n",
      "i\n",
      "z\n",
      "a\n",
      "n\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "“\n",
      "b\n",
      "o\n",
      "m\n",
      "b\n",
      "a\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "a\n",
      "r\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "\n",
      "“\n",
      "b\n",
      "a\n",
      "r\n",
      "a\n",
      "t\n",
      "o\n",
      "”\n",
      "?\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "o\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "(\n",
      "E\n",
      "x\n",
      ":\n",
      "\n",
      "T\n",
      "r\n",
      "a\n",
      "m\n",
      "a\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      "T\n",
      "i\n",
      "l\n",
      "e\n",
      "x\n",
      ",\n",
      "\n",
      "O\n",
      "x\n",
      "y\n",
      "c\n",
      "o\n",
      "t\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "F\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "n\n",
      "i\n",
      "l\n",
      ",\n",
      "\n",
      "e\n",
      "t\n",
      "c\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "o\n",
      "r\n",
      "m\n",
      "i\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "(\n",
      "E\n",
      "x\n",
      ":\n",
      "\n",
      "\n",
      "L\n",
      "e\n",
      "x\n",
      "o\n",
      "t\n",
      "a\n",
      "n\n",
      ",\n",
      "\n",
      "V\n",
      "a\n",
      "l\n",
      "i\n",
      "u\n",
      "m\n",
      ",\n",
      "\n",
      "L\n",
      "o\n",
      "r\n",
      "a\n",
      "x\n",
      ",\n",
      "\n",
      "R\n",
      "i\n",
      "v\n",
      "o\n",
      "t\n",
      "r\n",
      "i\n",
      "l\n",
      ",\n",
      "\n",
      "e\n",
      "t\n",
      "c\n",
      ")\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "e\n",
      "m\n",
      "a\n",
      "g\n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "E\n",
      "x\n",
      ":\n",
      "\n",
      "H\n",
      "i\n",
      "p\n",
      "o\n",
      "f\n",
      "a\n",
      "g\n",
      "i\n",
      "n\n",
      ",\n",
      "\n",
      "I\n",
      "n\n",
      "i\n",
      "b\n",
      "e\n",
      "x\n",
      ",\n",
      "\n",
      "D\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "r\n",
      "e\n",
      "b\n",
      "i\n",
      "t\n",
      "e\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O\n",
      "u\n",
      "t\n",
      "r\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "?\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "1\n",
      "6\n",
      ".\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "u\n",
      "s\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "s\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "s\n",
      "?\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "l\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "s\n",
      "a\n",
      "p\n",
      "a\n",
      "t\n",
      "e\n",
      "i\n",
      "r\n",
      "o\n",
      "\n",
      "\n",
      "S\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      ",\n",
      "\n",
      "t\n",
      "i\n",
      "n\n",
      "e\n",
      "r\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "l\n",
      "a\n",
      "n\n",
      "ç\n",
      "a\n",
      "-\n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "c\n",
      "a\n",
      "í\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "M\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "C\n",
      "r\n",
      "a\n",
      "c\n",
      "k\n",
      "\n",
      "\n",
      "E\n",
      "c\n",
      "s\n",
      "t\n",
      "a\n",
      "s\n",
      "y\n",
      "\n",
      "(\n",
      "M\n",
      "D\n",
      "M\n",
      "A\n",
      ",\n",
      "\n",
      "“\n",
      "b\n",
      "a\n",
      "l\n",
      "a\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "Á\n",
      "c\n",
      "i\n",
      "d\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "L\n",
      "S\n",
      "D\n",
      "\n",
      "(\n",
      "“\n",
      "d\n",
      "o\n",
      "c\n",
      "e\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      "i\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "a\n",
      "s\n",
      "p\n",
      "i\n",
      "r\n",
      "a\n",
      "d\n",
      "o\n",
      "/\n",
      "c\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "A\n",
      "n\n",
      "f\n",
      "e\n",
      "t\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "(\n",
      "“\n",
      "s\n",
      "p\n",
      "e\n",
      "e\n",
      "d\n",
      "”\n",
      ")\n",
      "\n",
      "(\n",
      "f\n",
      "u\n",
      "m\n",
      "a\n",
      "d\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "E\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "ó\n",
      "i\n",
      "d\n",
      "e\n",
      "s\n",
      "\n",
      "(\n",
      "a\n",
      "n\n",
      "a\n",
      "b\n",
      "o\n",
      "l\n",
      "i\n",
      "z\n",
      "a\n",
      "n\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "“\n",
      "b\n",
      "o\n",
      "m\n",
      "b\n",
      "a\n",
      "”\n",
      ")\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "a\n",
      "r\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "\n",
      "“\n",
      "b\n",
      "a\n",
      "r\n",
      "a\n",
      "t\n",
      "o\n",
      "”\n",
      "?\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "o\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "(\n",
      "E\n",
      "x\n",
      ":\n",
      "\n",
      "T\n",
      "r\n",
      "a\n",
      "m\n",
      "a\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      "T\n",
      "i\n",
      "l\n",
      "e\n",
      "x\n",
      ",\n",
      "\n",
      "O\n",
      "x\n",
      "y\n",
      "c\n",
      "o\n",
      "t\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "F\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "n\n",
      "i\n",
      "l\n",
      ",\n",
      "\n",
      "e\n",
      "t\n",
      "c\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "o\n",
      "r\n",
      "m\n",
      "i\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "(\n",
      "E\n",
      "x\n",
      ":\n",
      "\n",
      "\n",
      "L\n",
      "e\n",
      "x\n",
      "o\n",
      "t\n",
      "a\n",
      "n\n",
      ",\n",
      "\n",
      "V\n",
      "a\n",
      "l\n",
      "i\n",
      "u\n",
      "m\n",
      ",\n",
      "\n",
      "L\n",
      "o\n",
      "r\n",
      "a\n",
      "x\n",
      ",\n",
      "\n",
      "R\n",
      "i\n",
      "v\n",
      "o\n",
      "t\n",
      "r\n",
      "i\n",
      "l\n",
      ",\n",
      "\n",
      "e\n",
      "t\n",
      "c\n",
      ")\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "m\n",
      "é\n",
      "d\n",
      "i\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "e\n",
      "m\n",
      "a\n",
      "g\n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "r\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "E\n",
      "x\n",
      ":\n",
      "\n",
      "H\n",
      "i\n",
      "p\n",
      "o\n",
      "f\n",
      "a\n",
      "g\n",
      "i\n",
      "n\n",
      ",\n",
      "\n",
      "I\n",
      "n\n",
      "i\n",
      "b\n",
      "e\n",
      "x\n",
      ",\n",
      "\n",
      "D\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "r\n",
      "e\n",
      "b\n",
      "i\n",
      "t\n",
      "e\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "O\n",
      "u\n",
      "t\n",
      "r\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "?\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "1\n",
      "7\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "o\n",
      "\n",
      "u\n",
      "s\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "(\n",
      "s\n",
      ")\n",
      "\n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "â\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "(\n",
      "s\n",
      ")\n",
      "\n",
      "t\n",
      "e\n",
      "m\n",
      "\n",
      "\n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "(\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "s\n",
      "\n",
      "p\n",
      "a\n",
      "i\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "s\n",
      "\n",
      "a\n",
      "m\n",
      "i\n",
      "g\n",
      "o\n",
      "s\n",
      ",\n",
      "\n",
      "n\n",
      "a\n",
      "\n",
      "e\n",
      "s\n",
      "c\n",
      "o\n",
      "l\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "n\n",
      "o\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "b\n",
      "a\n",
      "l\n",
      "h\n",
      "o\n",
      ")\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "u\n",
      "s\n",
      "e\n",
      "i\n",
      "\n",
      "n\n",
      "e\n",
      "n\n",
      "h\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "â\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "R\n",
      "Ó\n",
      "X\n",
      "I\n",
      "M\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "E\n",
      "R\n",
      "G\n",
      "U\n",
      "N\n",
      "T\n",
      "A\n",
      "S\n",
      "\n",
      "S\n",
      "Ã\n",
      "O\n",
      "\n",
      "S\n",
      "O\n",
      "B\n",
      "R\n",
      "E\n",
      "\n",
      "M\n",
      "A\n",
      "C\n",
      "O\n",
      "N\n",
      "H\n",
      "A\n",
      "\n",
      "Q\n",
      "1\n",
      "8\n",
      ".\n",
      "\n",
      "A\n",
      "L\n",
      "G\n",
      "U\n",
      "M\n",
      "A\n",
      "\n",
      "V\n",
      "E\n",
      "Z\n",
      "\n",
      "N\n",
      "A\n",
      "\n",
      "V\n",
      "I\n",
      "D\n",
      "A\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "1\n",
      "9\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "I\n",
      "D\n",
      "A\n",
      "D\n",
      "E\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "i\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "e\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "u\n",
      "\n",
      "p\n",
      "e\n",
      "l\n",
      "a\n",
      "\n",
      "p\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "c\n",
      "i\n",
      "g\n",
      "a\n",
      "r\n",
      "r\n",
      "o\n",
      ")\n",
      "\n",
      "Q\n",
      "2\n",
      "0\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "c\n",
      "i\n",
      "g\n",
      "a\n",
      "r\n",
      "r\n",
      "o\n",
      ")\n",
      "\n",
      "Q\n",
      "2\n",
      "1\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "ê\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "1\n",
      "2\n",
      "\n",
      "M\n",
      "E\n",
      "S\n",
      "E\n",
      "S\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "U\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "M\n",
      "e\n",
      "n\n",
      "s\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "D\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "d\n",
      "i\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "e\n",
      "i\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "m\n",
      "e\n",
      "s\n",
      "e\n",
      "s\n",
      ")\n",
      "\n",
      "\n",
      "Q\n",
      "2\n",
      "2\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "a\n",
      "c\n",
      "h\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "\n",
      "u\n",
      "s\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "á\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "l\n",
      "e\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "À\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "F\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "Q\n",
      "2\n",
      "3\n",
      ".\n",
      "\n",
      "A\n",
      "\n",
      "i\n",
      "d\n",
      "e\n",
      "i\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "f\n",
      "u\n",
      "m\n",
      "a\n",
      "r\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "i\n",
      "x\n",
      "a\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "s\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "o\n",
      "c\n",
      "u\n",
      "p\n",
      "a\n",
      "d\n",
      "o\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "À\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "F\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "Q\n",
      "2\n",
      "4\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "o\n",
      "c\n",
      "u\n",
      "p\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "\n",
      "u\n",
      "s\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "À\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "F\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "Q\n",
      "2\n",
      "5\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "g\n",
      "o\n",
      "s\n",
      "t\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "r\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "À\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "F\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "Q\n",
      "2\n",
      "6\n",
      ".\n",
      "\n",
      "Q\n",
      "u\n",
      "ã\n",
      "o\n",
      "\n",
      "d\n",
      "i\n",
      "f\n",
      "í\n",
      "c\n",
      "i\n",
      "l\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "a\n",
      "c\n",
      "h\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "r\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "r\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "a\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "À\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "F\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "s\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "m\n",
      "p\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "D\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "v\n",
      "o\n",
      "l\n",
      "v\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "\n",
      "e\n",
      "\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "P\n",
      "E\n",
      "N\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "A\n",
      "R\n",
      "A\n",
      "\n",
      "M\n",
      "E\n",
      "N\n",
      "I\n",
      "N\n",
      "A\n",
      "S\n",
      "\n",
      "Q\n",
      "2\n",
      "7\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "o\n",
      "u\n",
      "?\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "2\n",
      "8\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "V\n",
      "O\n",
      "C\n",
      "Ê\n",
      "\n",
      "J\n",
      "Á\n",
      "\n",
      "M\n",
      "E\n",
      "N\n",
      "S\n",
      "T\n",
      "R\n",
      "U\n",
      "O\n",
      "U\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "p\n",
      "e\n",
      "l\n",
      "a\n",
      "\n",
      "p\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "?\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "e\n",
      "i\n",
      ")\n",
      "\n",
      "Q\n",
      "2\n",
      "9\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "e\n",
      "n\n",
      "g\n",
      "r\n",
      "a\n",
      "v\n",
      "i\n",
      "d\n",
      "o\n",
      "u\n",
      "?\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "3\n",
      "0\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "á\n",
      "\n",
      "g\n",
      "r\n",
      "á\n",
      "v\n",
      "i\n",
      "d\n",
      "a\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "e\n",
      "n\n",
      "g\n",
      "r\n",
      "a\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "i\n",
      ")\n",
      "\n",
      "Q\n",
      "3\n",
      "1\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "a\n",
      "b\n",
      "o\n",
      "r\n",
      "t\n",
      "o\n",
      "u\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "e\n",
      "n\n",
      "g\n",
      "r\n",
      "a\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "i\n",
      ")\n",
      "\n",
      "Q\n",
      "3\n",
      "2\n",
      ".\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "n\n",
      "t\n",
      "o\n",
      "s\n",
      "\n",
      "f\n",
      "i\n",
      "l\n",
      "h\n",
      "o\n",
      "s\n",
      "\n",
      "v\n",
      "i\n",
      "v\n",
      "o\n",
      "s\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "e\n",
      "m\n",
      "?\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "f\n",
      "i\n",
      "l\n",
      "h\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "t\n",
      "e\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "f\n",
      "i\n",
      "l\n",
      "h\n",
      "o\n",
      "s\n",
      ")\n",
      "\n",
      "\n",
      "Q\n",
      "3\n",
      "3\n",
      ".\n",
      "\n",
      "P\n",
      "o\n",
      "r\n",
      "\n",
      "f\n",
      "a\n",
      "v\n",
      "o\n",
      "r\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "r\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "u\n",
      "m\n",
      "\n",
      "X\n",
      "\n",
      "n\n",
      "o\n",
      "\n",
      "n\n",
      "ú\n",
      "m\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "d\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "i\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "a\n",
      "b\n",
      "a\n",
      "i\n",
      "x\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "m\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "i\n",
      "g\n",
      "o\n",
      "\n",
      "a\n",
      "g\n",
      "o\n",
      "r\n",
      "a\n",
      ":\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "1\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "2\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "3\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "4\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "5\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "1\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "2\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "3\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "4\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "5\n",
      "\n",
      "A\n",
      "P\n",
      "E\n",
      "N\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "A\n",
      "R\n",
      "A\n",
      "\n",
      "M\n",
      "E\n",
      "N\n",
      "I\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Q\n",
      "3\n",
      "5\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "e\n",
      "n\n",
      "g\n",
      "r\n",
      "a\n",
      "v\n",
      "i\n",
      "d\n",
      "o\n",
      "u\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "m\n",
      "e\n",
      "n\n",
      "i\n",
      "n\n",
      "a\n",
      "?\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "3\n",
      "6\n",
      ".\n",
      "\n",
      "A\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "m\n",
      "e\n",
      "n\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "e\n",
      "n\n",
      "g\n",
      "r\n",
      "a\n",
      "v\n",
      "i\n",
      "d\n",
      "o\n",
      "u\n",
      "\n",
      "f\n",
      "e\n",
      "z\n",
      "\n",
      "\n",
      "a\n",
      "b\n",
      "o\n",
      "r\n",
      "t\n",
      "o\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "e\n",
      "n\n",
      "g\n",
      "r\n",
      "a\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "i\n",
      "\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "u\n",
      "é\n",
      "m\n",
      ")\n",
      "\n",
      "Q\n",
      "3\n",
      "7\n",
      ".\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "n\n",
      "t\n",
      "o\n",
      "s\n",
      "\n",
      "f\n",
      "i\n",
      "l\n",
      "h\n",
      "o\n",
      "s\n",
      "\n",
      "v\n",
      "i\n",
      "v\n",
      "o\n",
      "s\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "e\n",
      "m\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "f\n",
      "i\n",
      "l\n",
      "h\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "t\n",
      "e\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "f\n",
      "i\n",
      "l\n",
      "h\n",
      "o\n",
      "s\n",
      ")\n",
      "\n",
      "\n",
      "Q\n",
      "3\n",
      "8\n",
      ".\n",
      "\n",
      "P\n",
      "o\n",
      "r\n",
      "\n",
      "f\n",
      "a\n",
      "v\n",
      "o\n",
      "r\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "r\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "u\n",
      "m\n",
      "\n",
      "X\n",
      "\n",
      "n\n",
      "o\n",
      "\n",
      "n\n",
      "ú\n",
      "m\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "d\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "i\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "a\n",
      "b\n",
      "a\n",
      "i\n",
      "x\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "m\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "i\n",
      "g\n",
      "o\n",
      "\n",
      "a\n",
      "g\n",
      "o\n",
      "r\n",
      "a\n",
      ":\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "1\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "2\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "3\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "4\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "Q\n",
      "3\n",
      "9\n",
      ".\n",
      "\n",
      "P\n",
      "o\n",
      "r\n",
      "\n",
      "f\n",
      "a\n",
      "v\n",
      "o\n",
      "r\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "r\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "u\n",
      "m\n",
      "\n",
      "X\n",
      "\n",
      "n\n",
      "o\n",
      "\n",
      "n\n",
      "ú\n",
      "m\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "d\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "i\n",
      "n\n",
      "h\n",
      "o\n",
      "\n",
      "a\n",
      "b\n",
      "a\n",
      "i\n",
      "x\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "m\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "i\n",
      "g\n",
      "o\n",
      "\n",
      "a\n",
      "g\n",
      "o\n",
      "r\n",
      "a\n",
      ":\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "1\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "2\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "3\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "4\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "d\n",
      "r\n",
      "o\n",
      "\n",
      "5\n",
      "\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "R\n",
      "Ó\n",
      "X\n",
      "I\n",
      "M\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "E\n",
      "R\n",
      "G\n",
      "U\n",
      "N\n",
      "T\n",
      "A\n",
      "S\n",
      "\n",
      "S\n",
      "Ã\n",
      "O\n",
      "\n",
      "S\n",
      "O\n",
      "B\n",
      "R\n",
      "E\n",
      "\n",
      "S\n",
      "E\n",
      "X\n",
      "U\n",
      "A\n",
      "L\n",
      "I\n",
      "D\n",
      "A\n",
      "D\n",
      "E\n",
      "\n",
      "E\n",
      "s\n",
      "s\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "s\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "e\n",
      "r\n",
      "g\n",
      "u\n",
      "n\n",
      "t\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "s\n",
      "o\n",
      "b\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "s\n",
      "u\n",
      "a\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "P\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "v\n",
      "o\n",
      "r\n",
      ",\n",
      "\n",
      "\n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "a\n",
      "\n",
      "\n",
      "e\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "o\n",
      "n\n",
      "d\n",
      "a\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "e\n",
      "r\n",
      "g\n",
      "u\n",
      "n\n",
      "t\n",
      "a\n",
      "s\n",
      "\n",
      "a\n",
      "b\n",
      "a\n",
      "i\n",
      "x\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "r\n",
      "d\n",
      "o\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "a\n",
      "\n",
      "m\n",
      "a\n",
      "n\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "a\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "c\n",
      "a\n",
      "d\n",
      "a\n",
      "\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "d\n",
      "a\n",
      "s\n",
      "\n",
      "o\n",
      "p\n",
      "ç\n",
      "õ\n",
      "e\n",
      "s\n",
      ".\n",
      "\n",
      "Q\n",
      "4\n",
      "8\n",
      ".\n",
      "\n",
      "S\n",
      "e\n",
      "x\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "a\n",
      "o\n",
      "\n",
      "\n",
      "n\n",
      "a\n",
      "s\n",
      "c\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "z\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "i\n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "d\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "\n",
      "n\n",
      "a\n",
      "s\n",
      "c\n",
      "e\n",
      "m\n",
      "o\n",
      "s\n",
      ".\n",
      "Q\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "o\n",
      "\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "\n",
      "n\n",
      "a\n",
      "s\n",
      "c\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "1\n",
      "\n",
      "M\n",
      "u\n",
      "l\n",
      "h\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "2\n",
      "\n",
      "H\n",
      "o\n",
      "m\n",
      "e\n",
      "m\n",
      "\n",
      "Q\n",
      "4\n",
      "9\n",
      ".\n",
      "\n",
      "I\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "G\n",
      "ê\n",
      "n\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "d\n",
      "i\n",
      "z\n",
      "\n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "i\n",
      "t\n",
      "o\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "n\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      ",\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "p\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "b\n",
      "e\n",
      "\n",
      "e\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "g\n",
      "o\n",
      "s\n",
      "t\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "a\n",
      "s\n",
      "\n",
      "o\n",
      "u\n",
      "t\n",
      "r\n",
      "a\n",
      "s\n",
      "\n",
      "p\n",
      "e\n",
      "s\n",
      "s\n",
      "o\n",
      "a\n",
      "s\n",
      "\n",
      "l\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "c\n",
      "o\n",
      "n\n",
      "h\n",
      "e\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      "e\n",
      "m\n",
      ".\n",
      "\n",
      "O\n",
      "u\n",
      "\n",
      "s\n",
      "e\n",
      "j\n",
      "a\n",
      ",\n",
      "\n",
      "é\n",
      "\n",
      "o\n",
      "\n",
      "g\n",
      "ê\n",
      "n\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      ".\n",
      "\n",
      "C\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "1\n",
      "\n",
      "M\n",
      "u\n",
      "l\n",
      "h\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "2\n",
      "\n",
      "H\n",
      "o\n",
      "m\n",
      "e\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "3\n",
      "\n",
      "M\n",
      "u\n",
      "l\n",
      "h\n",
      "e\n",
      "r\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "4\n",
      "\n",
      "H\n",
      "o\n",
      "m\n",
      "e\n",
      "m\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "5\n",
      "\n",
      "T\n",
      "r\n",
      "a\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "7\n",
      "\n",
      "O\n",
      "u\n",
      "t\n",
      "r\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "E\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "q\n",
      "u\n",
      "e\n",
      ":\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "9\n",
      "9\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "i\n",
      "\n",
      "Q\n",
      "5\n",
      "0\n",
      ".\n",
      "\n",
      "O\n",
      "r\n",
      "i\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "r\n",
      "e\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "a\n",
      "\n",
      "a\n",
      "t\n",
      "r\n",
      "a\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "a\n",
      "f\n",
      "e\n",
      "t\n",
      "i\n",
      "v\n",
      "a\n",
      ",\n",
      "\n",
      "f\n",
      "í\n",
      "s\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "r\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "o\n",
      "u\n",
      "t\n",
      "r\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "e\n",
      "s\n",
      "s\n",
      "o\n",
      "a\n",
      "s\n",
      ".\n",
      "\n",
      "Q\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "s\n",
      "u\n",
      "a\n",
      "\n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "1\n",
      "\n",
      "H\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "2\n",
      "\n",
      "B\n",
      "i\n",
      "s\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "3\n",
      "\n",
      "H\n",
      "o\n",
      "m\n",
      "o\n",
      "s\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "4\n",
      "\n",
      "A\n",
      "s\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "7\n",
      "\n",
      "O\n",
      "u\n",
      "t\n",
      "r\n",
      "a\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "Q\n",
      "5\n",
      "1\n",
      ".\n",
      "\n",
      "P\n",
      "r\n",
      "á\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      ".\n",
      "\n",
      "R\n",
      "e\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "-\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "m\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "z\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "o\n",
      ".\n",
      "\n",
      "\n",
      "C\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "m\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "f\n",
      "a\n",
      "z\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "o\n",
      "?\n",
      "\n",
      "M\n",
      "a\n",
      "r\n",
      "c\n",
      "a\n",
      "r\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      "d\n",
      "o\n",
      "s\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "p\n",
      "o\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "e\n",
      "m\n",
      "\n",
      "a\n",
      "o\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "m\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "z\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "o\n",
      ".\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "1\n",
      "\n",
      "M\n",
      "u\n",
      "l\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "\n",
      "[\n",
      "Q\n",
      "5\n",
      "1\n",
      "_\n",
      "1\n",
      "]\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "2\n",
      "\n",
      "H\n",
      "o\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "\n",
      "[\n",
      "Q\n",
      "5\n",
      "1\n",
      "_\n",
      "2\n",
      "]\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "3\n",
      "\n",
      "M\n",
      "u\n",
      "l\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "\n",
      "[\n",
      "Q\n",
      "5\n",
      "1\n",
      "_\n",
      "3\n",
      "]\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "4\n",
      "\n",
      "H\n",
      "o\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "\n",
      "[\n",
      "Q\n",
      "5\n",
      "1\n",
      "_\n",
      "4\n",
      "]\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "5\n",
      "\n",
      "T\n",
      "r\n",
      "a\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "s\n",
      "\n",
      "[\n",
      "Q\n",
      "5\n",
      "1\n",
      "_\n",
      "5\n",
      "]\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "7\n",
      "\n",
      "O\n",
      "u\n",
      "t\n",
      "r\n",
      "o\n",
      "s\n",
      "\n",
      "g\n",
      "ê\n",
      "n\n",
      "e\n",
      "r\n",
      "o\n",
      "s\n",
      "\n",
      "[\n",
      "Q\n",
      "5\n",
      "1\n",
      "_\n",
      "7\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "E\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "q\n",
      "u\n",
      "e\n",
      ":\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "Q\n",
      "5\n",
      "2\n",
      ".\n",
      "\n",
      "E\n",
      "x\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "G\n",
      "ê\n",
      "n\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "s\n",
      "a\n",
      "\n",
      "\n",
      "a\n",
      "p\n",
      "a\n",
      "r\n",
      "ê\n",
      "n\n",
      "c\n",
      "i\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "c\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "g\n",
      "o\n",
      "s\n",
      "t\n",
      "a\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "r\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "a\n",
      "r\n",
      "r\n",
      "u\n",
      "m\n",
      "a\n",
      "r\n",
      "\n",
      "\n",
      "o\n",
      "\n",
      "\n",
      "c\n",
      "a\n",
      "b\n",
      "e\n",
      "l\n",
      "o\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "a\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "s\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "(\n",
      "m\n",
      "o\n",
      "d\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "g\n",
      "i\n",
      "r\n",
      ",\n",
      "\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "l\n",
      "a\n",
      "r\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "n\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "v\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "m\n",
      "o\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "e\n",
      "\n",
      "g\n",
      "o\n",
      "s\n",
      "t\n",
      "a\n",
      "m\n",
      "o\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "D\n",
      "e\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "m\n",
      "a\n",
      "n\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "1\n",
      "\n",
      "T\n",
      "o\n",
      "t\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "f\n",
      "e\n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "2\n",
      "\n",
      "E\n",
      "m\n",
      "\n",
      "g\n",
      "r\n",
      "a\n",
      "n\n",
      "d\n",
      "e\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "e\n",
      "\n",
      "f\n",
      "e\n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "3\n",
      "\n",
      "A\n",
      "n\n",
      "d\n",
      "r\n",
      "ó\n",
      "g\n",
      "e\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "4\n",
      "\n",
      "E\n",
      "m\n",
      "\n",
      "g\n",
      "r\n",
      "a\n",
      "n\n",
      "d\n",
      "e\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "e\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "c\n",
      "u\n",
      "l\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "5\n",
      "\n",
      "T\n",
      "o\n",
      "t\n",
      "a\n",
      "l\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "c\n",
      "u\n",
      "l\n",
      "i\n",
      "n\n",
      "a\n",
      "\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "R\n",
      "Ó\n",
      "X\n",
      "I\n",
      "M\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "E\n",
      "R\n",
      "G\n",
      "U\n",
      "N\n",
      "T\n",
      "A\n",
      "S\n",
      "\n",
      "S\n",
      "Ã\n",
      "O\n",
      "\n",
      "S\n",
      "O\n",
      "B\n",
      "R\n",
      "E\n",
      "\n",
      "R\n",
      "E\n",
      "L\n",
      "A\n",
      "Ç\n",
      "Õ\n",
      "E\n",
      "S\n",
      "\n",
      "S\n",
      "E\n",
      "X\n",
      "U\n",
      "A\n",
      "I\n",
      "S\n",
      "\n",
      "Q\n",
      "4\n",
      "0\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "t\n",
      "e\n",
      "v\n",
      "e\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "(\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "o\n",
      "u\n",
      "?\n",
      ")\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "Q\n",
      "4\n",
      "1\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "V\n",
      "O\n",
      "C\n",
      "Ê\n",
      "\n",
      "J\n",
      "Á\n",
      "\n",
      "T\n",
      "E\n",
      "V\n",
      "E\n",
      "\n",
      "R\n",
      "E\n",
      "L\n",
      "A\n",
      "Ç\n",
      "Ã\n",
      "O\n",
      "\n",
      "S\n",
      "E\n",
      "X\n",
      "U\n",
      "A\n",
      "L\n",
      ",\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "e\n",
      "v\n",
      "e\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "p\n",
      "e\n",
      "l\n",
      "a\n",
      "\n",
      "p\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "i\n",
      "r\n",
      "a\n",
      "\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "e\n",
      "i\n",
      ")\n",
      "\n",
      "Q\n",
      "4\n",
      "2\n",
      ".\n",
      "\n",
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "j\n",
      "á\n",
      "\n",
      "f\n",
      "o\n",
      "i\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      "ç\n",
      "a\n",
      "d\n",
      "o\n",
      "(\n",
      "a\n",
      ")\n",
      "\n",
      "a\n",
      "\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "ç\n",
      "õ\n",
      "e\n",
      "s\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "é\n",
      "m\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "Q\n",
      "4\n",
      "3\n",
      ".\n",
      "\n",
      "Q\n",
      "u\n",
      "e\n",
      "\n",
      "i\n",
      "d\n",
      "a\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "t\n",
      "i\n",
      "n\n",
      "h\n",
      "a\n",
      "?\n",
      "\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ")\n",
      "\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "R\n",
      "Ó\n",
      "X\n",
      "I\n",
      "M\n",
      "A\n",
      "S\n",
      "\n",
      "P\n",
      "E\n",
      "R\n",
      "G\n",
      "U\n",
      "N\n",
      "T\n",
      "A\n",
      "S\n",
      "\n",
      "S\n",
      "Ã\n",
      "O\n",
      "\n",
      "S\n",
      "O\n",
      "B\n",
      "R\n",
      "E\n",
      "\n",
      "C\n",
      "O\n",
      "I\n",
      "S\n",
      "A\n",
      "S\n",
      "\n",
      "Q\n",
      "U\n",
      "E\n",
      "\n",
      "P\n",
      "O\n",
      "D\n",
      "E\n",
      "M\n",
      "\n",
      "T\n",
      "E\n",
      "R\n",
      "\n",
      "\n",
      "A\n",
      "C\n",
      "O\n",
      "N\n",
      "T\n",
      "E\n",
      "C\n",
      "I\n",
      "D\n",
      "O\n",
      "\n",
      "C\n",
      "O\n",
      "M\n",
      "\n",
      "V\n",
      "O\n",
      "C\n",
      "Ê\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "3\n",
      "\n",
      "A\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Q\n",
      "4\n",
      "2\n",
      ".\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "3\n",
      "\n",
      "A\n",
      "N\n",
      "O\n",
      "S\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "e\n",
      "r\n",
      "\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "a\n",
      "s\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "r\n",
      "\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      "a\n",
      "s\n",
      "\n",
      "s\n",
      "u\n",
      "j\n",
      "a\n",
      "s\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "s\n",
      "g\n",
      "a\n",
      "d\n",
      "a\n",
      "s\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      ",\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ";\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "J\n",
      "á\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "Q\n",
      "4\n",
      "3\n",
      ".\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "3\n",
      "\n",
      "A\n",
      "N\n",
      "O\n",
      "S\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "f\n",
      "o\n",
      "i\n",
      "\n",
      "\n",
      "x\n",
      "i\n",
      "n\n",
      "g\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "m\n",
      "\n",
      "a\n",
      "d\n",
      "u\n",
      "l\n",
      "t\n",
      "o\n",
      "\n",
      "(\n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "i\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "u\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "e\n",
      "\n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "l\n",
      "i\n",
      "a\n",
      "r\n",
      "e\n",
      "s\n",
      ")\n",
      ",\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "p\n",
      "a\n",
      "l\n",
      "a\n",
      "v\n",
      "r\n",
      "a\n",
      "s\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "o\n",
      "\n",
      "\n",
      "b\n",
      "u\n",
      "r\n",
      "r\n",
      "o\n",
      "(\n",
      "a\n",
      ")\n",
      ",\n",
      "\n",
      "i\n",
      "d\n",
      "i\n",
      "o\n",
      "t\n",
      "a\n",
      "(\n",
      "a\n",
      ")\n",
      ",\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "ú\n",
      "p\n",
      "i\n",
      "d\n",
      "o\n",
      "(\n",
      "a\n",
      ")\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      ",\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ";\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "J\n",
      "á\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "Q\n",
      "4\n",
      "4\n",
      ".\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "3\n",
      "\n",
      "A\n",
      "N\n",
      "O\n",
      "S\n",
      ",\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "u\n",
      "é\n",
      "m\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "s\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "i\n",
      "a\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "\n",
      "\n",
      "n\n",
      "a\n",
      "d\n",
      "a\n",
      ",\n",
      "\n",
      "g\n",
      "r\n",
      "i\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "b\n",
      "e\n",
      "r\n",
      "r\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      ",\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ";\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "J\n",
      "á\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "Q\n",
      "4\n",
      "5\n",
      ".\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "3\n",
      "\n",
      "A\n",
      "N\n",
      "O\n",
      "S\n",
      ",\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "a\n",
      "p\n",
      "a\n",
      "n\n",
      "h\n",
      "o\n",
      "u\n",
      "\n",
      "s\n",
      "e\n",
      "r\n",
      "i\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "u\n",
      "m\n",
      "\n",
      "a\n",
      "d\n",
      "u\n",
      "l\n",
      "t\n",
      "o\n",
      "\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "c\n",
      "a\n",
      "s\n",
      "a\n",
      ",\n",
      "\n",
      "c\n",
      "h\n",
      "e\n",
      "g\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "a\n",
      "\n",
      "d\n",
      "e\n",
      "i\n",
      "x\n",
      "a\n",
      "r\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "c\n",
      "h\n",
      "u\n",
      "c\n",
      "a\n",
      "d\n",
      "o\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "m\n",
      "a\n",
      "r\n",
      "c\n",
      "a\n",
      "s\n",
      "\n",
      "p\n",
      "e\n",
      "l\n",
      "o\n",
      "\n",
      "c\n",
      "o\n",
      "r\n",
      "p\n",
      "o\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      ",\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ";\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "J\n",
      "á\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "Q\n",
      "4\n",
      "6\n",
      ".\n",
      "\n",
      "N\n",
      "O\n",
      "S\n",
      "\n",
      "Ú\n",
      "L\n",
      "T\n",
      "I\n",
      "M\n",
      "O\n",
      "S\n",
      "\n",
      "3\n",
      "\n",
      "A\n",
      "N\n",
      "O\n",
      "S\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "m\n",
      "\n",
      "f\n",
      "e\n",
      "i\n",
      "t\n",
      "o\n",
      "s\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "s\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "i\n",
      "s\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "a\n",
      "m\n",
      "e\n",
      "a\n",
      "ç\n",
      "a\n",
      "r\n",
      "e\n",
      "m\n",
      "\n",
      "b\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "a\n",
      "l\n",
      "g\n",
      "o\n",
      "\n",
      "d\n",
      "o\n",
      "\n",
      "t\n",
      "i\n",
      "p\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "v\n",
      "o\n",
      "c\n",
      "ê\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "f\n",
      "i\n",
      "z\n",
      "e\n",
      "s\n",
      "s\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "i\n",
      "s\n",
      "a\n",
      "s\n",
      "\n",
      "s\n",
      "e\n",
      "x\n",
      "u\n",
      "a\n",
      "i\n",
      "s\n",
      "?\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      ",\n",
      "\n",
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ";\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "J\n",
      "á\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ",\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "o\n",
      "u\n",
      "\n",
      "d\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "e\n",
      "s\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "v\n",
      "e\n",
      "z\n",
      "\n",
      "e\n",
      "m\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "d\n",
      "o\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "S\n",
      "i\n",
      "m\n",
      ",\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "f\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "ú\n",
      "l\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "s\n",
      "\n",
      "3\n",
      "\n",
      "a\n",
      "n\n",
      "o\n",
      "s\n",
      ";\n",
      "\n",
      "\n",
      "Q\n",
      "4\n",
      "7\n",
      ".\n",
      "\n",
      "S\n",
      "E\n",
      "\n",
      "V\n",
      "O\n",
      "C\n",
      "Ê\n",
      "\n",
      "R\n",
      "E\n",
      "S\n",
      "P\n",
      "O\n",
      "N\n",
      "D\n",
      "E\n",
      "U\n",
      "\n",
      "S\n",
      "I\n",
      "M\n",
      "\n",
      "\n",
      "P\n",
      "A\n",
      "R\n",
      "A\n",
      "\n",
      "Q\n",
      "U\n",
      "A\n",
      "L\n",
      "Q\n",
      "U\n",
      "E\n",
      "R\n",
      "\n",
      "Q\n",
      "U\n",
      "E\n",
      "S\n",
      "T\n",
      "Ã\n",
      "O\n",
      "\n",
      "\n",
      "A\n",
      "C\n",
      "I\n",
      "M\n",
      "A\n",
      ",\n",
      "\n",
      "n\n",
      "o\n",
      "s\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "\n",
      "a\n",
      "s\n",
      "\n",
      "s\n",
      "u\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "l\n",
      "a\n",
      "v\n",
      "r\n",
      "a\n",
      "s\n",
      "\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "s\n",
      "e\n",
      "\n",
      "a\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "\n",
      "(\n",
      "n\n",
      "ã\n",
      "o\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n",
      "n\n",
      "e\n",
      "n\n",
      "h\n",
      "u\n",
      "m\n",
      "a\n",
      "\n",
      "s\n",
      "i\n",
      "t\n",
      "u\n",
      "a\n",
      "ç\n",
      "ã\n",
      "o\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "i\n",
      "g\n",
      "o\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "N\n",
      "ã\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "f\n",
      "a\n",
      "l\n",
      "a\n",
      "r\n",
      "\n",
      "s\n",
      "o\n",
      "b\n",
      "r\n",
      "e\n",
      "\n",
      "o\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "c\n",
      "e\n",
      "u\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Replace 'your_file.json' with the path to your actual JSON file\n",
    "file_path = './preprocessed_tables/012_hrcw2protocolopsicoconfmenor18.json'\n",
    "\n",
    "# Function to read the JSON file and process table cells\n",
    "def read_and_process_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    all_cells = []\n",
    "    for page_table in data['pageTables']:\n",
    "        for table in page_table['tables']:\n",
    "            for row in table:\n",
    "                # Assuming each row is a list and each cell text is an element of this list\n",
    "                # Adding each cell's text to the all_cells list\n",
    "                all_cells += [cell.strip() for cell in row if cell]  # Adding non-empty cells, stripped of whitespace\n",
    "\n",
    "    return all_cells\n",
    "\n",
    "# Call the function and print the result\n",
    "cells_list = read_and_process_json(file_path)\n",
    "for cell in cells_list:\n",
    "    print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path= r\"D:\\upwork\\Harmony\\new repo\\data\\preprocessed_tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_name= \"000_mfqchildselfreportshort.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE ', '1. I felt miserable or unhappy. ', ' ', ' ', ' ', '2. I didn’t enjoy anything at all. ', ' ', ' ', ' ', '3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' ', '4. I was very restless. ', ' ', ' ', ' ', '5. I felt I was no good anymore. ', ' ', ' ', ' ', '6. I cried a lot. ', ' ', ' ', ' ', '7. I found it hard to think properly or concentrate. ', ' ', ' ', ' ', '8. I hated myself. ', ' ', ' ', ' ', '9. I was a bad person. ', ' ', ' ', ' ', '10. I felt lonely. ', ' ', ' ', ' ', '11. I thought nobody really loved me. ', ' ', ' ', ' ', '12. I thought I could never be as good as other kids. ', ' ', ' ', ' ', '13. I did everything wrong. ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def extract_table_cells(json_file_path):\n",
    "    \"\"\"\n",
    "    Extracts each cell of a table from a JSON file into a Python list.\n",
    "\n",
    "    Parameters:\n",
    "    - json_file_path: str, path to the JSON file containing the table data\n",
    "\n",
    "    Returns:\n",
    "    - list, where each element is a cell from the table\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extract the table data\n",
    "    table_data = data['pageTables'][0]['tables']\n",
    "\n",
    "    # Create a list where each element is a cell from the table\n",
    "    cells_list = [cell for row in table_data for cell in row]\n",
    "\n",
    "    return cells_list\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = r'D:\\upwork\\Harmony\\new repo\\data\\preprocessed_tables\\000_mfqchildselfreportshort.json'\n",
    "\n",
    "# Extract the cells and print the result\n",
    "cells_list = extract_table_cells(json_file_path)\n",
    "print(cells_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not at allSeveral\\ndays\\nMore than\\nhalf the\\n...</td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Mode...</td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>15-19</td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Moderately severe depression</td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>20-27</td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Seve...</td>\n",
       "      <td>D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Cell Data   \n",
       "0   Not at allSeveral\\ndays\\nMore than\\nhalf the\\n...  \\\n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "58                                            Mode...   \n",
       "59                                             15-19    \n",
       "60                      Moderately severe depression    \n",
       "61    20-27                                             \n",
       "62                                            Seve...   \n",
       "\n",
       "                                             Filename  Table Number  \n",
       "0   D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             1  \n",
       "1   D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             1  \n",
       "2   D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             1  \n",
       "3   D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             1  \n",
       "4   D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             1  \n",
       "..                                                ...           ...  \n",
       "58  D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             2  \n",
       "59  D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             2  \n",
       "60  D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             2  \n",
       "61  D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             2  \n",
       "62  D:\\upwork\\Harmony\\new repo\\data\\preprocessed_t...             2  \n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def extract_cells_to_dataframe(json_file_path):\n",
    "    \"\"\"\n",
    "    Extracts table cells from a JSON file and creates a DataFrame with the cell data,\n",
    "    filename, and table number.\n",
    "\n",
    "    Parameters:\n",
    "    - json_file_path: str, path to the JSON file containing the table data\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame, with columns for cell data, filename, and table number\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Prepare data for DataFrame\n",
    "    df_data = []\n",
    "    filename = json_file_path.split('/')[-1]  # Extract filename from the path\n",
    "\n",
    "    # Iterate over each table in the JSON file\n",
    "    for table_number, table_info in enumerate(data['pageTables'], start=1):\n",
    "        table_data = table_info['tables']\n",
    "\n",
    "        # Iterate over each cell in the table\n",
    "        for row in table_data:\n",
    "            for cell in row:\n",
    "                df_data.append({\n",
    "                    'Cell Data': cell,\n",
    "                    'Filename': filename,\n",
    "                    'Table Number': table_number\n",
    "                })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Extract the cells into a DataFrame\n",
    "df = extract_cells_to_dataframe(r'D:\\upwork\\Harmony\\new repo\\data\\preprocessed_tables\\052_phq9iddate0803.json')\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Cell Data   \n",
      "0       To code, please use a checkmark () for each s...  \\\n",
      "1                                             NOT \\nTRUE    \n",
      "2                                           SOME \\nTIMES    \n",
      "3                                                   TRUE    \n",
      "4                        1. I felt miserable or unhappy.    \n",
      "...                                                   ...   \n",
      "100640                                                      \n",
      "100641                                                      \n",
      "100642                                                      \n",
      "100643                                                      \n",
      "100644                                                      \n",
      "\n",
      "                                Filename  Table Number  \n",
      "0       000_mfqchildselfreportshort.json             1  \n",
      "1       000_mfqchildselfreportshort.json             1  \n",
      "2       000_mfqchildselfreportshort.json             1  \n",
      "3       000_mfqchildselfreportshort.json             1  \n",
      "4       000_mfqchildselfreportshort.json             1  \n",
      "...                                  ...           ...  \n",
      "100640           064_hrcw1psicoconf.json             6  \n",
      "100641           064_hrcw1psicoconf.json             6  \n",
      "100642           064_hrcw1psicoconf.json             6  \n",
      "100643           064_hrcw1psicoconf.json             6  \n",
      "100644           064_hrcw1psicoconf.json             6  \n",
      "\n",
      "[100645 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "def extract_cells_to_dataframe(json_file_path):\n",
    "    # Load the JSON file with 'utf-8' encoding\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Prepare data for DataFrame\n",
    "    df_data = []\n",
    "    filename = os.path.basename(json_file_path)  # Extract filename in a cross-platform way\n",
    "\n",
    "    # Iterate over each table in the JSON file\n",
    "    for table_number, table_info in enumerate(data['pageTables'], start=1):\n",
    "        table_data = table_info['tables']\n",
    "\n",
    "        # Iterate over each cell in the table\n",
    "        for row in table_data:\n",
    "            for cell in row:\n",
    "                df_data.append({\n",
    "                    'Cell Data': cell,\n",
    "                    'Filename': filename,\n",
    "                    'Table Number': table_number\n",
    "                })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Directory path\n",
    "directory_path = r'D:\\upwork\\Harmony\\new repo\\data\\preprocessed_tables'\n",
    "\n",
    "# List all JSON files in the directory\n",
    "json_files = glob.glob(f\"{directory_path}/*.json\")\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file and extract data\n",
    "for file_path in json_files:\n",
    "    df = extract_cells_to_dataframe(file_path)\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "# all_data now contains the concatenated DataFrame of all files\n",
    "# Display the DataFrame\n",
    "print(all_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100640</th>\n",
       "      <td></td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100641</th>\n",
       "      <td></td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100642</th>\n",
       "      <td></td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100643</th>\n",
       "      <td></td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100644</th>\n",
       "      <td></td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100645 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Cell Data   \n",
       "0       To code, please use a checkmark () for each s...  \\\n",
       "1                                             NOT \\nTRUE    \n",
       "2                                           SOME \\nTIMES    \n",
       "3                                                   TRUE    \n",
       "4                        1. I felt miserable or unhappy.    \n",
       "...                                                   ...   \n",
       "100640                                                      \n",
       "100641                                                      \n",
       "100642                                                      \n",
       "100643                                                      \n",
       "100644                                                      \n",
       "\n",
       "                                Filename  Table Number  \n",
       "0       000_mfqchildselfreportshort.json             1  \n",
       "1       000_mfqchildselfreportshort.json             1  \n",
       "2       000_mfqchildselfreportshort.json             1  \n",
       "3       000_mfqchildselfreportshort.json             1  \n",
       "4       000_mfqchildselfreportshort.json             1  \n",
       "...                                  ...           ...  \n",
       "100640           064_hrcw1psicoconf.json             6  \n",
       "100641           064_hrcw1psicoconf.json             6  \n",
       "100642           064_hrcw1psicoconf.json             6  \n",
       "100643           064_hrcw1psicoconf.json             6  \n",
       "100644           064_hrcw1psicoconf.json             6  \n",
       "\n",
       "[100645 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filename\n",
       "015_hrcw1dom.json                          16713\n",
       "013_hrcw2protocolopsicoadultos.json        13255\n",
       "037_hrcw0dom.json                          12341\n",
       "027_hrcw2protocolodomiciliaradulto.json    12332\n",
       "016_hrcw2protocolodomiciliarmenor1.json    10360\n",
       "020_hrcw2protocolopsicomenor18.json         8592\n",
       "023_hrcw1psico.json                         8056\n",
       "054_class_teacher.json                      6324\n",
       "040_hrcw0psico.json                         5235\n",
       "049_hrcbscreen.json                         2608\n",
       "057_ndshs2016.json                          1739\n",
       "018_scaredformparentandchildversio.json      730\n",
       "012_hrcw2protocolopsicoconfmenor18.json      543\n",
       "048_hrcw2protocolopsicoconfadultos.json      476\n",
       "064_hrcw1psicoconf.json                      302\n",
       "053_neighbourhood.json                       288\n",
       "036_adhdquestionnaireasrs111.json            154\n",
       "028_mfqchildselfreportlong.json              136\n",
       "006_apadsm5severitymeasurefordepre.json      113\n",
       "051_dejonggierveldlonlinessscale.json        106\n",
       "052_phq9iddate0803.json                       63\n",
       "000_mfqchildselfreportshort.json              56\n",
       "008_gad7anxietyupdated0.json                  50\n",
       "059_foreign_affairs.json                      36\n",
       "038_mcs7youngpersononlinecawiquest.json       21\n",
       "001_patienthealthquestionnaire.json           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['Filename'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2. I didn’t enjoy anything at all.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3. I felt so tired I just sat around and did n...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4. I was very restless.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5. I felt I was no good anymore.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6. I cried a lot.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7. I found it hard to think properly or concen...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8. I hated myself.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9. I was a bad person.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10. I felt lonely.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11. I thought nobody really loved me.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>12. I thought I could never be as good as othe...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>13. I did everything wrong.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td></td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Cell Data   \n",
       "0   To code, please use a checkmark () for each s...  \\\n",
       "1                                         NOT \\nTRUE    \n",
       "2                                       SOME \\nTIMES    \n",
       "3                                               TRUE    \n",
       "4                    1. I felt miserable or unhappy.    \n",
       "5                                                       \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                 2. I didn’t enjoy anything at all.    \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12  3. I felt so tired I just sat around and did n...   \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                           4. I was very restless.    \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                  5. I felt I was no good anymore.    \n",
       "21                                                      \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                 6. I cried a lot.    \n",
       "25                                                      \n",
       "26                                                      \n",
       "27                                                      \n",
       "28  7. I found it hard to think properly or concen...   \n",
       "29                                                      \n",
       "30                                                      \n",
       "31                                                      \n",
       "32                                8. I hated myself.    \n",
       "33                                                      \n",
       "34                                                      \n",
       "35                                                      \n",
       "36                            9. I was a bad person.    \n",
       "37                                                      \n",
       "38                                                      \n",
       "39                                                      \n",
       "40                                10. I felt lonely.    \n",
       "41                                                      \n",
       "42                                                      \n",
       "43                                                      \n",
       "44             11. I thought nobody really loved me.    \n",
       "45                                                      \n",
       "46                                                      \n",
       "47                                                      \n",
       "48  12. I thought I could never be as good as othe...   \n",
       "49                                                      \n",
       "50                                                      \n",
       "51                                                      \n",
       "52                       13. I did everything wrong.    \n",
       "53                                                      \n",
       "54                                                      \n",
       "55                                                      \n",
       "\n",
       "                            Filename  Table Number  \n",
       "0   000_mfqchildselfreportshort.json             1  \n",
       "1   000_mfqchildselfreportshort.json             1  \n",
       "2   000_mfqchildselfreportshort.json             1  \n",
       "3   000_mfqchildselfreportshort.json             1  \n",
       "4   000_mfqchildselfreportshort.json             1  \n",
       "5   000_mfqchildselfreportshort.json             1  \n",
       "6   000_mfqchildselfreportshort.json             1  \n",
       "7   000_mfqchildselfreportshort.json             1  \n",
       "8   000_mfqchildselfreportshort.json             1  \n",
       "9   000_mfqchildselfreportshort.json             1  \n",
       "10  000_mfqchildselfreportshort.json             1  \n",
       "11  000_mfqchildselfreportshort.json             1  \n",
       "12  000_mfqchildselfreportshort.json             1  \n",
       "13  000_mfqchildselfreportshort.json             1  \n",
       "14  000_mfqchildselfreportshort.json             1  \n",
       "15  000_mfqchildselfreportshort.json             1  \n",
       "16  000_mfqchildselfreportshort.json             1  \n",
       "17  000_mfqchildselfreportshort.json             1  \n",
       "18  000_mfqchildselfreportshort.json             1  \n",
       "19  000_mfqchildselfreportshort.json             1  \n",
       "20  000_mfqchildselfreportshort.json             1  \n",
       "21  000_mfqchildselfreportshort.json             1  \n",
       "22  000_mfqchildselfreportshort.json             1  \n",
       "23  000_mfqchildselfreportshort.json             1  \n",
       "24  000_mfqchildselfreportshort.json             1  \n",
       "25  000_mfqchildselfreportshort.json             1  \n",
       "26  000_mfqchildselfreportshort.json             1  \n",
       "27  000_mfqchildselfreportshort.json             1  \n",
       "28  000_mfqchildselfreportshort.json             1  \n",
       "29  000_mfqchildselfreportshort.json             1  \n",
       "30  000_mfqchildselfreportshort.json             1  \n",
       "31  000_mfqchildselfreportshort.json             1  \n",
       "32  000_mfqchildselfreportshort.json             1  \n",
       "33  000_mfqchildselfreportshort.json             1  \n",
       "34  000_mfqchildselfreportshort.json             1  \n",
       "35  000_mfqchildselfreportshort.json             1  \n",
       "36  000_mfqchildselfreportshort.json             1  \n",
       "37  000_mfqchildselfreportshort.json             1  \n",
       "38  000_mfqchildselfreportshort.json             1  \n",
       "39  000_mfqchildselfreportshort.json             1  \n",
       "40  000_mfqchildselfreportshort.json             1  \n",
       "41  000_mfqchildselfreportshort.json             1  \n",
       "42  000_mfqchildselfreportshort.json             1  \n",
       "43  000_mfqchildselfreportshort.json             1  \n",
       "44  000_mfqchildselfreportshort.json             1  \n",
       "45  000_mfqchildselfreportshort.json             1  \n",
       "46  000_mfqchildselfreportshort.json             1  \n",
       "47  000_mfqchildselfreportshort.json             1  \n",
       "48  000_mfqchildselfreportshort.json             1  \n",
       "49  000_mfqchildselfreportshort.json             1  \n",
       "50  000_mfqchildselfreportshort.json             1  \n",
       "51  000_mfqchildselfreportshort.json             1  \n",
       "52  000_mfqchildselfreportshort.json             1  \n",
       "53  000_mfqchildselfreportshort.json             1  \n",
       "54  000_mfqchildselfreportshort.json             1  \n",
       "55  000_mfqchildselfreportshort.json             1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data['Filename']=='000_mfqchildselfreportshort.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14008\\1781442360.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Cell Data'] = df1['Cell Data'].str.strip()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14008\\1781442360.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Cell Data'].replace('', np.nan, inplace=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14008\\1781442360.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.dropna(subset=['Cell Data'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2. I didn’t enjoy anything at all.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3. I felt so tired I just sat around and did n...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4. I was very restless.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5. I felt I was no good anymore.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6. I cried a lot.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7. I found it hard to think properly or concen...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8. I hated myself.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9. I was a bad person.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10. I felt lonely.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11. I thought nobody really loved me.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>12. I thought I could never be as good as othe...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>13. I did everything wrong.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Cell Data   \n",
       "0   To code, please use a checkmark () for each s...  \\\n",
       "1                                          NOT \\nTRUE   \n",
       "2                                        SOME \\nTIMES   \n",
       "3                                                TRUE   \n",
       "4                     1. I felt miserable or unhappy.   \n",
       "8                  2. I didn’t enjoy anything at all.   \n",
       "12  3. I felt so tired I just sat around and did n...   \n",
       "16                            4. I was very restless.   \n",
       "20                   5. I felt I was no good anymore.   \n",
       "24                                  6. I cried a lot.   \n",
       "28  7. I found it hard to think properly or concen...   \n",
       "32                                 8. I hated myself.   \n",
       "36                             9. I was a bad person.   \n",
       "40                                 10. I felt lonely.   \n",
       "44              11. I thought nobody really loved me.   \n",
       "48  12. I thought I could never be as good as othe...   \n",
       "52                        13. I did everything wrong.   \n",
       "\n",
       "                            Filename  Table Number  \n",
       "0   000_mfqchildselfreportshort.json             1  \n",
       "1   000_mfqchildselfreportshort.json             1  \n",
       "2   000_mfqchildselfreportshort.json             1  \n",
       "3   000_mfqchildselfreportshort.json             1  \n",
       "4   000_mfqchildselfreportshort.json             1  \n",
       "8   000_mfqchildselfreportshort.json             1  \n",
       "12  000_mfqchildselfreportshort.json             1  \n",
       "16  000_mfqchildselfreportshort.json             1  \n",
       "20  000_mfqchildselfreportshort.json             1  \n",
       "24  000_mfqchildselfreportshort.json             1  \n",
       "28  000_mfqchildselfreportshort.json             1  \n",
       "32  000_mfqchildselfreportshort.json             1  \n",
       "36  000_mfqchildselfreportshort.json             1  \n",
       "40  000_mfqchildselfreportshort.json             1  \n",
       "44  000_mfqchildselfreportshort.json             1  \n",
       "48  000_mfqchildselfreportshort.json             1  \n",
       "52  000_mfqchildselfreportshort.json             1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df1=all_data[all_data['Filename']=='000_mfqchildselfreportshort.json']\n",
    "\n",
    "# Strip leading and trailing whitespace\n",
    "df1['Cell Data'] = df1['Cell Data'].str.strip()\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df1['Cell Data'].replace('', np.nan, inplace=True)\n",
    "\n",
    "# Drop rows where 'Cell Data' is NaN\n",
    "df1.dropna(subset=['Cell Data'], inplace=True)\n",
    "\n",
    "# Now df1 should have the null/empty rows removed\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip leading and trailing whitespace\n",
    "all_data['Cell Data'] = all_data['Cell Data'].str.strip()\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "all_data['Cell Data'].replace('', np.nan, inplace=True)\n",
    "\n",
    "# Drop rows where 'Cell Data' is NaN\n",
    "all_data.dropna(subset=['Cell Data'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>000_mfqchildselfreportshort.json</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100594</th>\n",
       "      <td>_______ filhos \\n(   ) 99 Não se aplica (não t...</td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100603</th>\n",
       "      <td>Q34. Por favor, marque com um X no número do q...</td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100615</th>\n",
       "      <td>(   ) Quadro 1 (   ) Quadro 2 (   ) Quadro 4 (...</td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100627</th>\n",
       "      <td>Q35. Por favor, marque com um X no número do q...</td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100639</th>\n",
       "      <td>(   ) Quadro 1 (   ) Quadro 2 (   ) Quadro 4 (...</td>\n",
       "      <td>064_hrcw1psicoconf.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16909 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Cell Data   \n",
       "0       To code, please use a checkmark () for each s...  \\\n",
       "1                                              NOT \\nTRUE   \n",
       "2                                            SOME \\nTIMES   \n",
       "3                                                    TRUE   \n",
       "4                         1. I felt miserable or unhappy.   \n",
       "...                                                   ...   \n",
       "100594  _______ filhos \\n(   ) 99 Não se aplica (não t...   \n",
       "100603  Q34. Por favor, marque com um X no número do q...   \n",
       "100615  (   ) Quadro 1 (   ) Quadro 2 (   ) Quadro 4 (...   \n",
       "100627  Q35. Por favor, marque com um X no número do q...   \n",
       "100639  (   ) Quadro 1 (   ) Quadro 2 (   ) Quadro 4 (...   \n",
       "\n",
       "                                Filename  Table Number  \n",
       "0       000_mfqchildselfreportshort.json             1  \n",
       "1       000_mfqchildselfreportshort.json             1  \n",
       "2       000_mfqchildselfreportshort.json             1  \n",
       "3       000_mfqchildselfreportshort.json             1  \n",
       "4       000_mfqchildselfreportshort.json             1  \n",
       "...                                  ...           ...  \n",
       "100594           064_hrcw1psicoconf.json             6  \n",
       "100603           064_hrcw1psicoconf.json             6  \n",
       "100615           064_hrcw1psicoconf.json             6  \n",
       "100627           064_hrcw1psicoconf.json             6  \n",
       "100639           064_hrcw1psicoconf.json             6  \n",
       "\n",
       "[16909 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be simple survey question like \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like question.\n",
      "\n",
      "***Cell to annotate****\n",
      "What is your age?\n",
      "\n",
      "Does the cell contain a question? (yes/no)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"{filename}\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
    "\n",
    "Filename: {filename}\n",
    "JSON Table Structure:\n",
    "{json_table_structure}\n",
    "\n",
    "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
    "- If the cell content is a question, mark it as \"yes\".\n",
    "- If the cell content is not a question, mark it as \"no\".\n",
    "\n",
    "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
    "\n",
    "there can be simple survey question like \n",
    "I felt I was no good anymore\n",
    "I cried a lot.\n",
    "\n",
    "Basically you will have to look into json structure and see if this looks like question.\n",
    "\n",
    "***Cell to annotate****\n",
    "{cell_data}\n",
    "\n",
    "Does the cell contain a question? (yes/no)\n",
    "\"\"\"\n",
    "\n",
    "# Example usage with dynamic filename and dummy data\n",
    "filename = \"000_mfqchildselfreportshort.json\"  # Dynamic filename\n",
    "#json_table_structure = '{\"tableNumber\": 1, \"data\": [[\"What is your age?\", \"Age\"], [\"20\", \"Patient Age\"]]}'  # Replace this with actual JSON structure from the file\n",
    "#json_table_structure\n",
    "\n",
    "with open(os.path.join(directory_path,filename), 'r', encoding='utf-8') as file:\n",
    "    json_table_structure = str(json.load(file))\n",
    "\n",
    "cell_data = \"What is your age?\"  # This is the cell content you want to annotate\n",
    "\n",
    "prompt = prompt_template.format(filename=filename, json_table_structure=json_table_structure, cell_data=cell_data)\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "To code, please use a checkmark () for each statement.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "NOT \n",
      "TRUE\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "SOME \n",
      "TIMES\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "TRUE\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "1. I felt miserable or unhappy.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "2. I didn’t enjoy anything at all.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "3. I felt so tired I just sat around and did nothing.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "4. I was very restless.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "5. I felt I was no good anymore.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "6. I cried a lot.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "7. I found it hard to think properly or concentrate.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "8. I hated myself.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "9. I was a bad person.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "10. I felt lonely.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "11. I thought nobody really loved me.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "12. I thought I could never be as good as other kids.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n",
      "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"000_mfqchildselfreportshort.json\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
      "\n",
      "Filename: 000_mfqchildselfreportshort.json\n",
      "JSON Table Structure:\n",
      "{'pageTables': [{'page': 1, 'tables': [['To code, please use a checkmark (\\uf0fc) for each statement. ', 'NOT \\nTRUE ', 'SOME \\nTIMES ', 'TRUE '], ['1. I felt miserable or unhappy. ', ' ', ' ', ' '], ['2. I didn’t enjoy anything at all. ', ' ', ' ', ' '], ['3. I felt so tired I just sat around and did nothing. ', ' ', ' ', ' '], ['4. I was very restless. ', ' ', ' ', ' '], ['5. I felt I was no good anymore. ', ' ', ' ', ' '], ['6. I cried a lot. ', ' ', ' ', ' '], ['7. I found it hard to think properly or concentrate. ', ' ', ' ', ' '], ['8. I hated myself. ', ' ', ' ', ' '], ['9. I was a bad person. ', ' ', ' ', ' '], ['10. I felt lonely. ', ' ', ' ', ' '], ['11. I thought nobody really loved me. ', ' ', ' ', ' '], ['12. I thought I could never be as good as other kids. ', ' ', ' ', ' '], ['13. I did everything wrong. ', ' ', ' ', ' ']], 'merges': {}, 'merge_alias': {}, 'width': 4, 'height': 14}], 'numPages': 1, 'currentPages': 1}\n",
      "\n",
      "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
      "- If the cell content is a question, mark it as \"yes\".\n",
      "- If the cell content is not a question, mark it as \"no\".\n",
      "\n",
      "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
      "\n",
      "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
      "I felt I was no good anymore\n",
      "I cried a lot.\n",
      "\n",
      "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
      "\n",
      "***Cell to annotate***\n",
      "13. I did everything wrong.\n",
      "\n",
      "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cell_data in df1['Cell Data']:\n",
    "    prompt_template = \"\"\"\\\n",
    "I need your help to determine whether each cell in a table is a question or not. The table is extracted from the file named \"{filename}\". Here's the structure of a table in JSON format, followed by a specific cell for you to annotate.\n",
    "\n",
    "Filename: {filename}\n",
    "JSON Table Structure:\n",
    "{json_table_structure}\n",
    "\n",
    "Please analyze the cell data provided and determine if it forms a question or a statement. Here are the guidelines for annotation:\n",
    "- If the cell content is a question, mark it as \"yes\".\n",
    "- If the cell content is not a question, mark it as \"no\".\n",
    "\n",
    "For example, if the cell says \"What is your age?\", your response should be \"yes\" because it is a question. If the cell says \"Age of the patient\", your response should be \"no\" because it is not a question.\n",
    "\n",
    "there can be survey question which are not why, how, what in nature but just interrogative or seeking 'Yes/No' response from the patient/user so carefully mark such as Yes if found: \n",
    "I felt I was no good anymore\n",
    "I cried a lot.\n",
    "\n",
    "Basically you will have to look into json structure and see if this looks like survey question (keep in mind survey questions looks like simple statement most of the time but those should be marked as questions).\n",
    "\n",
    "***Cell to annotate***\n",
    "{cell_data}\n",
    "\n",
    "Do not get confused with instructions as questions. your job is to identify is it is survey question or not.\n",
    "\n",
    "Without any explaination respond. Does the cell contain a question? (yes/no)\n",
    "\"\"\"\n",
    "\n",
    "    # Example usage with dynamic filename and dummy data\n",
    "    filename = \"000_mfqchildselfreportshort.json\"  # Dynamic filename\n",
    "    #json_table_structure = '{\"tableNumber\": 1, \"data\": [[\"What is your age?\", \"Age\"], [\"20\", \"Patient Age\"]]}'  # Replace this with actual JSON structure from the file\n",
    "    #json_table_structure\n",
    "\n",
    "    with open(os.path.join(directory_path,filename), 'r', encoding='utf-8') as file:\n",
    "        json_table_structure = str(json.load(file))\n",
    "\n",
    "    #cell_data = \"What is your age?\"  # This is the cell content you want to annotate\n",
    "\n",
    "    prompt = prompt_template.format(filename=filename, json_table_structure=json_table_structure, cell_data=cell_data)\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(r\"D:\\upwork\\Harmony\\pdf_extraction_experiments-main\\pdf_extraction_experiments-main\\annotated_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8387096774193549\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       320\n",
      "           1       0.85      0.27      0.40        83\n",
      "\n",
      "    accuracy                           0.84       403\n",
      "   macro avg       0.84      0.63      0.66       403\n",
      "weighted avg       0.84      0.84      0.80       403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Custom transformer that integrates NLTK preprocessing\n",
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self, stop_words='english', lower=True, strip=True):\n",
    "        self.stop_words = set(stopwords.words(stop_words)) if stop_words else None\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.lower = lower\n",
    "        self.strip = strip\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            self.preprocess(text) for text in X\n",
    "        ]\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        if self.lower:\n",
    "            text = text.lower()\n",
    "        if self.strip:\n",
    "            text = text.strip()\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        # Lemmatization and stop words removal\n",
    "        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words and token.isalpha()]\n",
    "        return ' '.join(lemmatized_tokens)\n",
    "\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# Update the pipeline to include the custom text preprocessing\n",
    "model = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(stop_words='english')),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['y'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that vectorizes the text and then applies a Naive Bayes model\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = list(class_weight.compute_class_weight(class_weight= 'balanced',\n",
    "                                             classes = np.unique(df['y']),\n",
    "                                             y = df['y']))\n",
    "\n",
    "#df['Product'].value_counts()\n",
    "\n",
    "class_weights.sort()\n",
    "\n",
    "class_weights\n",
    "\n",
    "weights={}\n",
    "\n",
    "\n",
    "for index, weight in enumerate(class_weights) :\n",
    "    weights[index]=weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6194581280788177, 1: 2.5927835051546393}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/5\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 822ms/step - accuracy: 0.4893 - loss: 0.6749 - val_accuracy: 0.6287 - val_loss: 0.6886\n",
      "Epoch 2/5\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 790ms/step - accuracy: 0.8013 - loss: 0.3711 - val_accuracy: 0.8713 - val_loss: 0.2566\n",
      "Epoch 3/5\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 797ms/step - accuracy: 0.9375 - loss: 0.1797 - val_accuracy: 0.8465 - val_loss: 0.3422\n",
      "Epoch 4/5\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 786ms/step - accuracy: 0.9565 - loss: 0.0992 - val_accuracy: 0.8911 - val_loss: 0.2882\n",
      "Epoch 5/5\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 796ms/step - accuracy: 0.9859 - loss: 0.0439 - val_accuracy: 0.8861 - val_loss: 0.3033\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "embedding_dim = 64  # Dimension of the embedding layer\n",
    "max_length = 200    # Maximum length of all sequences\n",
    "trunc_type = 'post' # Truncating sequences from the end\n",
    "padding_type = 'post' # Padding sequences at the end\n",
    "oov_tok = '<OOV>'   # Token for out of vocabulary words\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['y'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "\n",
    "model= tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    #tf.keras.layers.Dropout(0.1)\n",
    "    tf.keras.layers.Dense(embedding_dim, activation= 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Overview of the model\n",
    "print(model.summary())\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_padded, np.array(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_padded, np.array(y_test)),\n",
    "    class_weight=weights,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred= model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8959501e-04],\n",
       "       [6.2463910e-04],\n",
       "       [4.8766920e-01],\n",
       "       [3.3287969e-04],\n",
       "       [3.7192586e-01],\n",
       "       [2.0767398e-01],\n",
       "       [2.3337931e-03],\n",
       "       [4.0024632e-04],\n",
       "       [9.8851889e-01],\n",
       "       [9.7788742e-04],\n",
       "       [6.4513052e-04],\n",
       "       [9.8676223e-01],\n",
       "       [5.0628209e-04],\n",
       "       [3.7926668e-04],\n",
       "       [2.9886345e-04],\n",
       "       [3.2557521e-04],\n",
       "       [3.1805597e-04],\n",
       "       [7.2975614e-04],\n",
       "       [3.6480566e-04],\n",
       "       [5.0206828e-01],\n",
       "       [3.4751042e-04],\n",
       "       [1.4107266e-03],\n",
       "       [9.8491222e-01],\n",
       "       [6.8569556e-04],\n",
       "       [2.7100678e-04],\n",
       "       [2.9694347e-04],\n",
       "       [4.0080299e-04],\n",
       "       [1.0806331e-03],\n",
       "       [1.4032833e-01],\n",
       "       [3.0946513e-04],\n",
       "       [3.1675867e-04],\n",
       "       [3.8901874e-04],\n",
       "       [4.0492031e-04],\n",
       "       [9.8924720e-01],\n",
       "       [3.8362612e-04],\n",
       "       [4.6404891e-04],\n",
       "       [2.7871568e-04],\n",
       "       [3.2515245e-04],\n",
       "       [1.4123500e-03],\n",
       "       [9.7834222e-02],\n",
       "       [7.9817674e-04],\n",
       "       [9.8931855e-01],\n",
       "       [1.1195412e-03],\n",
       "       [9.8720956e-01],\n",
       "       [3.0854510e-04],\n",
       "       [9.8952067e-01],\n",
       "       [3.9541174e-04],\n",
       "       [4.4410056e-01],\n",
       "       [4.2507620e-04],\n",
       "       [3.6700201e-04],\n",
       "       [4.0545795e-04],\n",
       "       [4.4081296e-04],\n",
       "       [2.7581872e-04],\n",
       "       [3.2072398e-04],\n",
       "       [3.1675899e-04],\n",
       "       [5.2532612e-04],\n",
       "       [4.9907621e-02],\n",
       "       [9.8895854e-01],\n",
       "       [3.9554448e-04],\n",
       "       [3.5767138e-04],\n",
       "       [3.5424955e-04],\n",
       "       [3.2117781e-01],\n",
       "       [5.3256599e-04],\n",
       "       [4.1491367e-04],\n",
       "       [3.7994198e-04],\n",
       "       [6.2651086e-01],\n",
       "       [6.9175370e-04],\n",
       "       [5.2532612e-04],\n",
       "       [4.6051107e-04],\n",
       "       [3.3195046e-04],\n",
       "       [3.3072929e-04],\n",
       "       [4.3979258e-04],\n",
       "       [9.2376548e-01],\n",
       "       [3.0950055e-04],\n",
       "       [9.8620391e-01],\n",
       "       [3.1183384e-04],\n",
       "       [2.9079115e-04],\n",
       "       [5.9961923e-04],\n",
       "       [3.4076074e-04],\n",
       "       [1.0170701e-01],\n",
       "       [3.4683160e-04],\n",
       "       [8.4780892e-03],\n",
       "       [9.0202367e-01],\n",
       "       [3.0537107e-04],\n",
       "       [4.2564163e-04],\n",
       "       [9.8906159e-01],\n",
       "       [5.5771868e-04],\n",
       "       [9.8920155e-01],\n",
       "       [7.7132782e-04],\n",
       "       [8.0158841e-04],\n",
       "       [4.2972490e-04],\n",
       "       [3.5257387e-04],\n",
       "       [7.9391990e-03],\n",
       "       [4.2952708e-04],\n",
       "       [5.3441082e-04],\n",
       "       [3.5861885e-04],\n",
       "       [9.6077740e-01],\n",
       "       [4.4219129e-04],\n",
       "       [3.7994198e-04],\n",
       "       [4.3299617e-04],\n",
       "       [9.8905170e-01],\n",
       "       [3.0160675e-04],\n",
       "       [6.1626959e-04],\n",
       "       [5.1497039e-03],\n",
       "       [3.4909832e-04],\n",
       "       [3.4533860e-04],\n",
       "       [5.3207780e-04],\n",
       "       [3.4717235e-04],\n",
       "       [3.7336972e-04],\n",
       "       [4.2972490e-04],\n",
       "       [3.9597036e-04],\n",
       "       [1.0387914e-03],\n",
       "       [9.8759937e-01],\n",
       "       [5.2611611e-04],\n",
       "       [4.3222215e-04],\n",
       "       [8.7158215e-01],\n",
       "       [9.8633289e-01],\n",
       "       [1.0959602e-02],\n",
       "       [2.7327234e-01],\n",
       "       [1.2062238e-02],\n",
       "       [5.0230160e-02],\n",
       "       [4.5090233e-04],\n",
       "       [8.6585033e-01],\n",
       "       [3.9420303e-04],\n",
       "       [3.6526780e-04],\n",
       "       [3.8274773e-04],\n",
       "       [9.8870277e-01],\n",
       "       [9.8726112e-01],\n",
       "       [5.4116524e-04],\n",
       "       [4.1838703e-04],\n",
       "       [7.4248791e-01],\n",
       "       [9.8931819e-01],\n",
       "       [9.8897642e-01],\n",
       "       [5.0700695e-04],\n",
       "       [1.3749885e-03],\n",
       "       [3.3940212e-04],\n",
       "       [1.9571109e-02],\n",
       "       [3.7545362e-04],\n",
       "       [7.1008307e-01],\n",
       "       [6.0330296e-04],\n",
       "       [4.6233292e-04],\n",
       "       [5.7590124e-04],\n",
       "       [5.5316940e-04],\n",
       "       [8.2418439e-04],\n",
       "       [5.4303563e-01],\n",
       "       [9.8925173e-01],\n",
       "       [6.0555881e-01],\n",
       "       [7.6137553e-03],\n",
       "       [3.3984779e-04],\n",
       "       [3.0883998e-04],\n",
       "       [3.7994198e-04],\n",
       "       [7.9463208e-01],\n",
       "       [1.0619698e-03],\n",
       "       [9.8851204e-01],\n",
       "       [9.7250551e-01],\n",
       "       [7.6164876e-04],\n",
       "       [1.0425667e-02],\n",
       "       [9.8929387e-01],\n",
       "       [9.4582676e-04],\n",
       "       [3.9282290e-04],\n",
       "       [3.0872872e-04],\n",
       "       [3.0271600e-03],\n",
       "       [4.0976916e-04],\n",
       "       [1.1121293e-03],\n",
       "       [5.1363447e-04],\n",
       "       [4.7205776e-04],\n",
       "       [9.8948252e-01],\n",
       "       [8.1377942e-04],\n",
       "       [8.6681187e-01],\n",
       "       [3.5356852e-04],\n",
       "       [3.4656833e-04],\n",
       "       [3.6794215e-01],\n",
       "       [1.8194027e-03],\n",
       "       [9.9182433e-01],\n",
       "       [3.4062999e-01],\n",
       "       [3.3140503e-04],\n",
       "       [6.2828476e-04],\n",
       "       [5.1389722e-04],\n",
       "       [3.9120307e-04],\n",
       "       [4.8583475e-04],\n",
       "       [3.3870665e-04],\n",
       "       [3.1829561e-04],\n",
       "       [6.1727362e-04],\n",
       "       [3.8362612e-04],\n",
       "       [5.9476413e-04],\n",
       "       [4.7532484e-04],\n",
       "       [9.3009539e-02],\n",
       "       [9.8889947e-01],\n",
       "       [3.8822187e-04],\n",
       "       [8.3156460e-04],\n",
       "       [4.5966331e-04],\n",
       "       [9.8899847e-01],\n",
       "       [8.7158215e-01],\n",
       "       [3.1435405e-04],\n",
       "       [3.7823172e-04],\n",
       "       [5.0522032e-04],\n",
       "       [4.0398783e-04],\n",
       "       [5.2532612e-04],\n",
       "       [3.2517040e-01],\n",
       "       [1.3163127e-03],\n",
       "       [5.0585752e-04],\n",
       "       [3.6172319e-04]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(test_padded)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_labels = (y_pred > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317    0\n",
       "526     0\n",
       "393     0\n",
       "1405    0\n",
       "433     1\n",
       "       ..\n",
       "1473    0\n",
       "554     0\n",
       "963     0\n",
       "1618    0\n",
       "721     0\n",
       "Name: y, Length: 202, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317    0\n",
       "526     0\n",
       "393     0\n",
       "1405    0\n",
       "433     1\n",
       "       ..\n",
       "733     1\n",
       "1474    0\n",
       "692     0\n",
       "1767    0\n",
       "1624    0\n",
       "Name: y, Length: 403, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01031934],\n",
       "       [0.00561864],\n",
       "       [0.34470615],\n",
       "       [0.00182583],\n",
       "       [0.24392697],\n",
       "       [0.35356227],\n",
       "       [0.02295132],\n",
       "       [0.007709  ],\n",
       "       [0.953778  ],\n",
       "       [0.0109594 ],\n",
       "       [0.0225505 ],\n",
       "       [0.9431978 ],\n",
       "       [0.0203615 ],\n",
       "       [0.0020606 ],\n",
       "       [0.00149843],\n",
       "       [0.00174641],\n",
       "       [0.00166697],\n",
       "       [0.00467662],\n",
       "       [0.00366546],\n",
       "       [0.08095002],\n",
       "       [0.00354409],\n",
       "       [0.22122438],\n",
       "       [0.9492299 ],\n",
       "       [0.01431693],\n",
       "       [0.00139033],\n",
       "       [0.00180096],\n",
       "       [0.00210871],\n",
       "       [0.5986805 ],\n",
       "       [0.22915861],\n",
       "       [0.00153795],\n",
       "       [0.00146436],\n",
       "       [0.00240157],\n",
       "       [0.00209706],\n",
       "       [0.9548645 ],\n",
       "       [0.00201217],\n",
       "       [0.00327001],\n",
       "       [0.00143279],\n",
       "       [0.00179278],\n",
       "       [0.0383339 ],\n",
       "       [0.9427289 ],\n",
       "       [0.00496302],\n",
       "       [0.954333  ],\n",
       "       [0.00710286],\n",
       "       [0.93067926],\n",
       "       [0.00162192],\n",
       "       [0.9548893 ],\n",
       "       [0.00288687],\n",
       "       [0.26395157],\n",
       "       [0.00285703],\n",
       "       [0.0018575 ],\n",
       "       [0.00206221],\n",
       "       [0.00267851],\n",
       "       [0.00125787],\n",
       "       [0.00167822],\n",
       "       [0.00146436],\n",
       "       [0.00285703],\n",
       "       [0.52624714],\n",
       "       [0.9540813 ],\n",
       "       [0.00212429],\n",
       "       [0.0018584 ],\n",
       "       [0.0030137 ],\n",
       "       [0.6166594 ],\n",
       "       [0.00393281],\n",
       "       [0.00297085],\n",
       "       [0.00372284],\n",
       "       [0.3903364 ],\n",
       "       [0.00395706],\n",
       "       [0.00285703],\n",
       "       [0.0032515 ],\n",
       "       [0.00404281],\n",
       "       [0.00202689],\n",
       "       [0.00319912],\n",
       "       [0.9448187 ],\n",
       "       [0.00187989],\n",
       "       [0.9545047 ],\n",
       "       [0.00154201],\n",
       "       [0.00130582],\n",
       "       [0.01004728],\n",
       "       [0.0020033 ],\n",
       "       [0.0066219 ],\n",
       "       [0.00343547],\n",
       "       [0.11725364],\n",
       "       [0.6779572 ],\n",
       "       [0.00154457],\n",
       "       [0.00372517],\n",
       "       [0.9535668 ],\n",
       "       [0.01127598],\n",
       "       [0.9539452 ],\n",
       "       [0.00777345],\n",
       "       [0.0182047 ],\n",
       "       [0.0056715 ],\n",
       "       [0.00173999],\n",
       "       [0.20943294],\n",
       "       [0.002254  ],\n",
       "       [0.0060777 ],\n",
       "       [0.00200787],\n",
       "       [0.03097231],\n",
       "       [0.00276517],\n",
       "       [0.00372284],\n",
       "       [0.0024798 ],\n",
       "       [0.9545007 ],\n",
       "       [0.00174679],\n",
       "       [0.0077556 ],\n",
       "       [0.04165533],\n",
       "       [0.00194605],\n",
       "       [0.00285703],\n",
       "       [0.00527213],\n",
       "       [0.00231959],\n",
       "       [0.00249965],\n",
       "       [0.0056715 ],\n",
       "       [0.00210516],\n",
       "       [0.00467249],\n",
       "       [0.95424193],\n",
       "       [0.00729348],\n",
       "       [0.00816028],\n",
       "       [0.78325063],\n",
       "       [0.9518339 ],\n",
       "       [0.02294113],\n",
       "       [0.66319096],\n",
       "       [0.120474  ],\n",
       "       [0.03220608],\n",
       "       [0.00219684],\n",
       "       [0.91041297],\n",
       "       [0.00244498],\n",
       "       [0.00331757],\n",
       "       [0.00253205],\n",
       "       [0.95526314],\n",
       "       [0.9501205 ],\n",
       "       [0.00275606],\n",
       "       [0.0020548 ],\n",
       "       [0.7904328 ],\n",
       "       [0.9550538 ],\n",
       "       [0.9528778 ],\n",
       "       [0.00446703],\n",
       "       [0.02002108],\n",
       "       [0.00153507],\n",
       "       [0.29134125],\n",
       "       [0.00178376],\n",
       "       [0.9182558 ],\n",
       "       [0.00428691],\n",
       "       [0.00474148],\n",
       "       [0.00253878],\n",
       "       [0.00445393],\n",
       "       [0.01559678],\n",
       "       [0.94038874],\n",
       "       [0.95454043],\n",
       "       [0.92241555],\n",
       "       [0.07018609],\n",
       "       [0.00134377],\n",
       "       [0.00267202],\n",
       "       [0.00372284],\n",
       "       [0.39201006],\n",
       "       [0.01317463],\n",
       "       [0.9533366 ],\n",
       "       [0.9380072 ],\n",
       "       [0.00725019],\n",
       "       [0.02345986],\n",
       "       [0.9540963 ],\n",
       "       [0.02696522],\n",
       "       [0.00244263],\n",
       "       [0.00187208],\n",
       "       [0.0063181 ],\n",
       "       [0.00373111],\n",
       "       [0.03442817],\n",
       "       [0.0039449 ],\n",
       "       [0.00365315],\n",
       "       [0.9549648 ],\n",
       "       [0.02180485],\n",
       "       [0.93570244],\n",
       "       [0.00222103],\n",
       "       [0.00320045],\n",
       "       [0.74095535],\n",
       "       [0.11303575],\n",
       "       [0.9556396 ],\n",
       "       [0.09182646],\n",
       "       [0.00178855],\n",
       "       [0.00413262],\n",
       "       [0.00424887],\n",
       "       [0.00215356],\n",
       "       [0.0027491 ],\n",
       "       [0.00306555],\n",
       "       [0.00146566],\n",
       "       [0.01070093],\n",
       "       [0.00201217],\n",
       "       [0.00709521],\n",
       "       [0.00771574],\n",
       "       [0.502975  ],\n",
       "       [0.95399415],\n",
       "       [0.00660269],\n",
       "       [0.01623032],\n",
       "       [0.01113571],\n",
       "       [0.95513767],\n",
       "       [0.78325063],\n",
       "       [0.00206   ],\n",
       "       [0.00225351],\n",
       "       [0.00574003],\n",
       "       [0.00226164],\n",
       "       [0.00285703],\n",
       "       [0.60001206],\n",
       "       [0.03689845],\n",
       "       [0.01222057],\n",
       "       [0.00220739],\n",
       "       [0.00285703],\n",
       "       [0.00173687],\n",
       "       [0.00154457],\n",
       "       [0.00146436],\n",
       "       [0.00413223],\n",
       "       [0.00194996],\n",
       "       [0.00117555],\n",
       "       [0.34227163],\n",
       "       [0.00650817],\n",
       "       [0.95396227],\n",
       "       [0.00298436],\n",
       "       [0.9546293 ],\n",
       "       [0.9546273 ],\n",
       "       [0.9551552 ],\n",
       "       [0.0018584 ],\n",
       "       [0.9533714 ],\n",
       "       [0.00421942],\n",
       "       [0.00240509],\n",
       "       [0.00263512],\n",
       "       [0.00146436],\n",
       "       [0.29435226],\n",
       "       [0.9547264 ],\n",
       "       [0.9549531 ],\n",
       "       [0.00153795],\n",
       "       [0.00237486],\n",
       "       [0.00339732],\n",
       "       [0.8794978 ],\n",
       "       [0.00680623],\n",
       "       [0.00144655],\n",
       "       [0.18419668],\n",
       "       [0.9506693 ],\n",
       "       [0.00318505],\n",
       "       [0.9557913 ],\n",
       "       [0.00162976],\n",
       "       [0.00770859],\n",
       "       [0.00233395],\n",
       "       [0.9546742 ],\n",
       "       [0.00267554],\n",
       "       [0.00266874],\n",
       "       [0.00459289],\n",
       "       [0.00149389],\n",
       "       [0.00222878],\n",
       "       [0.00385059],\n",
       "       [0.18786113],\n",
       "       [0.01655756],\n",
       "       [0.9559639 ],\n",
       "       [0.00209537],\n",
       "       [0.94894624],\n",
       "       [0.00634332],\n",
       "       [0.95454043],\n",
       "       [0.00162976],\n",
       "       [0.066009  ],\n",
       "       [0.00189891],\n",
       "       [0.00200828],\n",
       "       [0.003048  ],\n",
       "       [0.00198618],\n",
       "       [0.09743658],\n",
       "       [0.00146436],\n",
       "       [0.00133344],\n",
       "       [0.00974364],\n",
       "       [0.00201953],\n",
       "       [0.00258939],\n",
       "       [0.80519736],\n",
       "       [0.00244498],\n",
       "       [0.00875239],\n",
       "       [0.88262725],\n",
       "       [0.01752873],\n",
       "       [0.10741445],\n",
       "       [0.00246324],\n",
       "       [0.00199325],\n",
       "       [0.00186243],\n",
       "       [0.09277181],\n",
       "       [0.954114  ],\n",
       "       [0.9524737 ],\n",
       "       [0.00666195],\n",
       "       [0.3717776 ],\n",
       "       [0.00601004],\n",
       "       [0.2957013 ],\n",
       "       [0.00319912],\n",
       "       [0.00483991],\n",
       "       [0.0119125 ],\n",
       "       [0.0045685 ],\n",
       "       [0.00188859],\n",
       "       [0.95402455],\n",
       "       [0.9544744 ],\n",
       "       [0.00415956],\n",
       "       [0.00258518],\n",
       "       [0.00166005],\n",
       "       [0.00235326],\n",
       "       [0.9527781 ],\n",
       "       [0.91556907],\n",
       "       [0.00147664],\n",
       "       [0.04974568],\n",
       "       [0.0033729 ],\n",
       "       [0.00916449],\n",
       "       [0.9555399 ],\n",
       "       [0.00554436],\n",
       "       [0.9552447 ],\n",
       "       [0.00285703],\n",
       "       [0.95476866],\n",
       "       [0.00212454],\n",
       "       [0.00207241],\n",
       "       [0.00223206],\n",
       "       [0.11691913],\n",
       "       [0.9543126 ],\n",
       "       [0.00285703],\n",
       "       [0.00212454],\n",
       "       [0.1305884 ],\n",
       "       [0.00248957],\n",
       "       [0.01512407],\n",
       "       [0.00165649],\n",
       "       [0.00376202],\n",
       "       [0.00146436],\n",
       "       [0.47846073],\n",
       "       [0.9554867 ],\n",
       "       [0.00509088],\n",
       "       [0.00536204],\n",
       "       [0.01006648],\n",
       "       [0.02027673],\n",
       "       [0.0020676 ],\n",
       "       [0.00153795],\n",
       "       [0.00146109],\n",
       "       [0.00162976],\n",
       "       [0.0019926 ],\n",
       "       [0.03943161],\n",
       "       [0.00296313],\n",
       "       [0.9519086 ],\n",
       "       [0.00132389],\n",
       "       [0.03592341],\n",
       "       [0.9454553 ],\n",
       "       [0.39855912],\n",
       "       [0.01276148],\n",
       "       [0.01833623],\n",
       "       [0.0013171 ],\n",
       "       [0.05130241],\n",
       "       [0.00460534],\n",
       "       [0.00324479],\n",
       "       [0.00328793],\n",
       "       [0.00285703],\n",
       "       [0.00167822],\n",
       "       [0.00775413],\n",
       "       [0.94387984],\n",
       "       [0.00187393],\n",
       "       [0.00153795],\n",
       "       [0.94572407],\n",
       "       [0.9486002 ],\n",
       "       [0.00147664],\n",
       "       [0.00895353],\n",
       "       [0.4433246 ],\n",
       "       [0.953554  ],\n",
       "       [0.00159882],\n",
       "       [0.00238581],\n",
       "       [0.95082885],\n",
       "       [0.0932956 ],\n",
       "       [0.00258518],\n",
       "       [0.9476775 ],\n",
       "       [0.04745145],\n",
       "       [0.01698576],\n",
       "       [0.00415956],\n",
       "       [0.00149389],\n",
       "       [0.00779937],\n",
       "       [0.00285703],\n",
       "       [0.9330325 ],\n",
       "       [0.05287948],\n",
       "       [0.00255141],\n",
       "       [0.00626626],\n",
       "       [0.00202943],\n",
       "       [0.00162976],\n",
       "       [0.00935377],\n",
       "       [0.17235914],\n",
       "       [0.01492433],\n",
       "       [0.00285703],\n",
       "       [0.9542689 ],\n",
       "       [0.95066243],\n",
       "       [0.00129126],\n",
       "       [0.92689896],\n",
       "       [0.58583146],\n",
       "       [0.8245191 ],\n",
       "       [0.9522761 ],\n",
       "       [0.01187515],\n",
       "       [0.91271716],\n",
       "       [0.00190036],\n",
       "       [0.95327246],\n",
       "       [0.00194397],\n",
       "       [0.00132166],\n",
       "       [0.00906179],\n",
       "       [0.00337498],\n",
       "       [0.00628   ],\n",
       "       [0.05159491],\n",
       "       [0.14668457],\n",
       "       [0.00244939],\n",
       "       [0.00149963],\n",
       "       [0.7620991 ],\n",
       "       [0.00544265],\n",
       "       [0.00488076],\n",
       "       [0.9500701 ],\n",
       "       [0.9549355 ],\n",
       "       [0.00203352],\n",
       "       [0.00871605],\n",
       "       [0.00711582],\n",
       "       [0.86067176]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification= classification_report(y_test, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       320\n",
      "           1       0.73      0.81      0.77        83\n",
      "\n",
      "    accuracy                           0.90       403\n",
      "   macro avg       0.84      0.86      0.85       403\n",
      "weighted avg       0.90      0.90      0.90       403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       163\n",
      "           1       0.70      0.72      0.71        39\n",
      "\n",
      "    accuracy                           0.89       202\n",
      "   macro avg       0.82      0.82      0.82       202\n",
      "weighted avg       0.89      0.89      0.89       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification= classification_report(y_test, y_pred_labels)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Define the path to the folder containing the CSV files\n",
    "# folder_path = r'C:\\Users\\HP\\Downloads\\processed\\processed'\n",
    "\n",
    "# # List to hold dataframes\n",
    "# dfs = []\n",
    "\n",
    "# # Loop through all files in the folder\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "#         df = pd.read_csv(file_path)  # Load the CSV file\n",
    "#         if 'Cell Data' in df.columns:  # Check if 'Text' column exists\n",
    "#             dfs.append(df[['Cell Data', 'IsQuestion']])  # Append only the 'Text' column to the list\n",
    "\n",
    "# # Concatenate all dataframes in the list\n",
    "# combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# # # If you want to save the combined dataframe to a new CSV file\n",
    "# # combined_df.to_csv('combined_csv.csv', index=False)\n",
    "\n",
    "# # Show the first few rows of the combined dataframe\n",
    "# combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "      <th>IsQuestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Cell Data  \\\n",
       "0  To code, please use a checkmark () for each s...   \n",
       "1                                         NOT \\nTRUE   \n",
       "2                                       SOME \\nTIMES   \n",
       "3                                               TRUE   \n",
       "4                    1. I felt miserable or unhappy.   \n",
       "\n",
       "                                            Filename  Table Number  IsQuestion  \n",
       "0  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "1  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "2  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "3  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "4  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = r'C:\\Users\\tates\\Classwork\\open-source\\harmony\\processed'\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)  # Load the CSV file\n",
    "        \n",
    "        # Check if 'IsQuestion' column exists\n",
    "        if 'IsQuestion' in df.columns:\n",
    "            # Convert NaN values to 0 and then the column to integers\n",
    "            df['IsQuestion'] = df['IsQuestion'].fillna(0).astype(int)\n",
    "            dfs.append(df)  # Append the dataframe to the list\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# If you want to save the combined dataframe to a new CSV file\n",
    "# combined_df.to_csv('combined_csv.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the combined dataframe\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "      <th>IsQuestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2. I didn’t enjoy anything at all.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3. I felt so tired I just sat around and did n...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4. I was very restless.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5. I felt I was no good anymore.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6. I cried a lot.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7. I found it hard to think properly or concen...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8. I hated myself.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9. I was a bad person.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10. I felt lonely.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11. I thought nobody really loved me.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12. I thought I could never be as good as othe...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13. I did everything wrong.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PATIENT HEALTH QUESTIONNAIRE-9  \\n(PHQ-9) \\nOv...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1. Little interest or pleasure in doing things...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2. Feeling down, depressed, or hopeless 0     ...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Cell Data  \\\n",
       "0   To code, please use a checkmark () for each s...   \n",
       "1                                          NOT \\nTRUE   \n",
       "2                                        SOME \\nTIMES   \n",
       "3                                                TRUE   \n",
       "4                     1. I felt miserable or unhappy.   \n",
       "5                  2. I didn’t enjoy anything at all.   \n",
       "6   3. I felt so tired I just sat around and did n...   \n",
       "7                             4. I was very restless.   \n",
       "8                    5. I felt I was no good anymore.   \n",
       "9                                   6. I cried a lot.   \n",
       "10  7. I found it hard to think properly or concen...   \n",
       "11                                 8. I hated myself.   \n",
       "12                             9. I was a bad person.   \n",
       "13                                 10. I felt lonely.   \n",
       "14              11. I thought nobody really loved me.   \n",
       "15  12. I thought I could never be as good as othe...   \n",
       "16                        13. I did everything wrong.   \n",
       "17  PATIENT HEALTH QUESTIONNAIRE-9  \\n(PHQ-9) \\nOv...   \n",
       "18  1. Little interest or pleasure in doing things...   \n",
       "19  2. Feeling down, depressed, or hopeless 0     ...   \n",
       "\n",
       "                                             Filename  Table Number  \\\n",
       "0   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "1   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "2   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "3   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "4   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "5   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "6   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "7   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "8   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "9   C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "10  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "11  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "12  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "13  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "14  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "15  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "16  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "17  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "18  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "19  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1   \n",
       "\n",
       "    IsQuestion  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            1  \n",
       "9            1  \n",
       "10           1  \n",
       "11           1  \n",
       "12           1  \n",
       "13           1  \n",
       "14           1  \n",
       "15           1  \n",
       "16           1  \n",
       "17           0  \n",
       "18           1  \n",
       "19           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsQuestion\n",
       "0    680\n",
       "1    348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['IsQuestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_9 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 826ms/step - accuracy: 0.3363 - loss: 0.8261 - val_accuracy: 0.7670 - val_loss: 0.6938\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 726ms/step - accuracy: 0.8285 - loss: 0.4351 - val_accuracy: 0.9612 - val_loss: 0.1663\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 756ms/step - accuracy: 0.9441 - loss: 0.1692 - val_accuracy: 0.9806 - val_loss: 0.1152\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 744ms/step - accuracy: 0.9807 - loss: 0.0744 - val_accuracy: 0.9515 - val_loss: 0.0829\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 753ms/step - accuracy: 0.9902 - loss: 0.0374 - val_accuracy: 0.9709 - val_loss: 0.0602\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "embedding_dim = 64  # Dimension of the embedding layer\n",
    "max_length = 200    # Maximum length of all sequences\n",
    "trunc_type = 'post' # Truncating sequences from the end\n",
    "padding_type = 'post' # Padding sequences at the end\n",
    "oov_tok = '<OOV>'   # Token for out of vocabulary words\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'], combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "\n",
    "model= tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    #tf.keras.layers.Dropout(0.1)\n",
    "    tf.keras.layers.Dense(embedding_dim, activation= 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Overview of the model\n",
    "print(model.summary())\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_padded, np.array(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_padded, np.array(y_test)),\n",
    "    class_weight=weights,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 527ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred= model.predict(test_padded)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_labels = (y_pred > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        74\n",
      "           1       0.93      0.97      0.95        29\n",
      "\n",
      "    accuracy                           0.97       103\n",
      "   macro avg       0.96      0.97      0.96       103\n",
      "weighted avg       0.97      0.97      0.97       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification= classification_report(y_test, y_pred_labels)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "      <th>IsQuestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Cell Data   \n",
       "0  To code, please use a checkmark () for each s...  \\\n",
       "1                                         NOT \\nTRUE   \n",
       "2                                       SOME \\nTIMES   \n",
       "3                                               TRUE   \n",
       "4                    1. I felt miserable or unhappy.   \n",
       "\n",
       "                                            Filename  Table Number  IsQuestion  \n",
       "0  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "1  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "2  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "3  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "4  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM with sentence transformers as embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = list(class_weight.compute_class_weight(class_weight= 'balanced',\n",
    "                                             classes = np.unique(combined_df['IsQuestion']),\n",
    "                                             y = combined_df['IsQuestion']))\n",
    "\n",
    "#df['Product'].value_counts()\n",
    "\n",
    "class_weights.sort()\n",
    "\n",
    "class_weights\n",
    "\n",
    "weights={}\n",
    "\n",
    "\n",
    "for index, weight in enumerate(class_weights) :\n",
    "    weights[index]=weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7558823529411764, 1: 1.4770114942528736}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f410adb5e6254449b1b9cc33b7c54747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd98c61a8561436b93381c627339f270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_16                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,362,368</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_17                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">918,528</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_16                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │     \u001b[38;5;34m2,362,368\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_17                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m918,528\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,297,409</span> (12.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,297,409\u001b[0m (12.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,297,409</span> (12.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,297,409\u001b[0m (12.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.8250 - loss: 0.5496 - val_accuracy: 0.9320 - val_loss: 0.1638\n",
      "Epoch 2/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9612 - loss: 0.1235 - val_accuracy: 0.9320 - val_loss: 0.1477\n",
      "Epoch 3/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9784 - loss: 0.0697 - val_accuracy: 0.9612 - val_loss: 0.0931\n",
      "Epoch 4/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9823 - loss: 0.0592 - val_accuracy: 0.9612 - val_loss: 0.0689\n",
      "Epoch 5/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9899 - loss: 0.0359 - val_accuracy: 0.9612 - val_loss: 0.0578\n",
      "Epoch 6/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9879 - loss: 0.0255 - val_accuracy: 0.9612 - val_loss: 0.0376\n",
      "Epoch 7/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9923 - loss: 0.0128 - val_accuracy: 0.9709 - val_loss: 0.0306\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming 'combined_df' is your DataFrame containing the data\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 384  # Adjusted to match the Sentence Transformer model's embedding size\n",
    "\n",
    "# Load the pretrained Sentence Transformer model\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Function to preprocess text data using Sentence Transformer\n",
    "def get_embeddings(sentences):\n",
    "    return sentence_model.encode(sentences, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'], combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert X_train and X_test to lists to ensure proper indexing\n",
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()\n",
    "\n",
    "# Preprocess the text data to get embeddings\n",
    "train_embeddings = get_embeddings(X_train_list)\n",
    "test_embeddings = get_embeddings(X_test_list)\n",
    "\n",
    "# Reshape the embeddings to add a \"sequence\" dimension\n",
    "train_embeddings = np.expand_dims(train_embeddings, axis=1)\n",
    "test_embeddings = np.expand_dims(test_embeddings, axis=1)\n",
    "\n",
    "# LSTM Model Architecture\n",
    "model = tf.keras.Sequential([\n",
    "    # Input shape is now (1, embedding_dim) since we're treating each embedding as a single timestep\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim, return_sequences=True), input_shape=(1, embedding_dim)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False)),  # Example dimension reduction\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Example additional dense layer\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Overview of the model\n",
    "model.summary()\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "epochs = 7\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_embeddings, np.array(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_embeddings, np.array(y_test)),\n",
    "    \n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9960 - loss: 0.0100 - val_accuracy: 0.9903 - val_loss: 0.0284\n",
      "Epoch 2/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9987 - loss: 0.0061 - val_accuracy: 0.9903 - val_loss: 0.0385\n",
      "Epoch 3/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.9903 - val_loss: 0.0377\n",
      "Epoch 4/7\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.9903 - val_loss: 0.0499\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_embeddings, np.array(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_embeddings, np.array(y_test)),\n",
    "    class_weight=weights,  # Ensure 'weights' is defined as per your original code\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_embeddings)\n",
    "\n",
    "threshold = 0.9\n",
    "y_pred_labels = (y_pred > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        74\n",
      "           1       0.97      1.00      0.98        29\n",
      "\n",
      "    accuracy                           0.99       103\n",
      "   macro avg       0.98      0.99      0.99       103\n",
      "weighted avg       0.99      0.99      0.99       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "classification= classification_report(y_test, y_pred_labels)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        74\n",
      "           1       0.97      1.00      0.98        29\n",
      "\n",
      "    accuracy                           0.99       103\n",
      "   macro avg       0.98      0.99      0.99       103\n",
      "weighted avg       0.99      0.99      0.99       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "classification= classification_report(y_test, y_pred_labels)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9320388349514563\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        74\n",
      "           1       1.00      0.76      0.86        29\n",
      "\n",
      "    accuracy                           0.93       103\n",
      "   macro avg       0.96      0.88      0.91       103\n",
      "weighted avg       0.94      0.93      0.93       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Custom transformer that integrates NLTK preprocessing\n",
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self, stop_words='english', lower=True, strip=True):\n",
    "        self.stop_words = set(stopwords.words(stop_words)) if stop_words else None\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.lower = lower\n",
    "        self.strip = strip\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            self.preprocess(text) for text in X\n",
    "        ]\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        if self.lower:\n",
    "            text = text.lower()\n",
    "        if self.strip:\n",
    "            text = text.strip()\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        # Lemmatization and stop words removal\n",
    "        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words and token.isalpha()]\n",
    "        return ' '.join(lemmatized_tokens)\n",
    "\n",
    "combined_df['Cell Data']= combined_df['Cell Data'].fillna('')\n",
    "\n",
    "# Update the pipeline to include the custom text preprocessing\n",
    "model = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(stop_words='english')),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['text'], df['y'], test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'], combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Create a pipeline that vectorizes the text and then applies a Naive Bayes model\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive bayes with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abf76e31b994902a8eee8bba95024ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444b28c65309431484ca3f9521c97faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8543689320388349\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89        74\n",
      "           1       0.68      0.93      0.78        29\n",
      "\n",
      "    accuracy                           0.85       103\n",
      "   macro avg       0.82      0.88      0.84       103\n",
      "weighted avg       0.89      0.85      0.86       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'combined_df' is your DataFrame\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Function to preprocess text data using Sentence Transformer\n",
    "def get_embeddings(sentences):\n",
    "    return sentence_model.encode(sentences, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'], combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert texts to embeddings\n",
    "X_train_embeddings = get_embeddings(X_train.tolist())\n",
    "X_test_embeddings = get_embeddings(X_test.tolist())\n",
    "\n",
    "# Since Naive Bayes in sklearn does not directly support sparse input, we use GaussianNB which expects dense input\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# Train the Gaussian Naive Bayes model\n",
    "classifier.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = classifier.predict(X_test_embeddings)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTransformerEmbedder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to fit\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Convert texts to embeddings\n",
    "        embeddings = self.model.encode(X, show_progress_bar=True)\n",
    "        return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0321967e2ec04b3487ffa3d2aef42f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8543689320388349\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89        74\n",
      "           1       0.68      0.93      0.78        29\n",
      "\n",
      "    accuracy                           0.85       103\n",
      "   macro avg       0.82      0.88      0.84       103\n",
      "weighted avg       0.89      0.85      0.86       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'combined_df' is your DataFrame and has been defined\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'].fillna(''), combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Ensure X_train and X_test are lists\n",
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()\n",
    "\n",
    "# Initialize the pipeline\n",
    "model = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000)),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "model.fit(X_train_list, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d5a984a9a649ed8633f3507e98c42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078f41ecd22e465eaf1ee9e64de48613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9805825242718447\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        74\n",
      "           1       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.98       103\n",
      "   macro avg       0.99      0.97      0.98       103\n",
      "weighted avg       0.98      0.98      0.98       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the pipeline with Random Forest Classifier\n",
    "model = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "])\n",
    "\n",
    "# Train the model with X_train_list and y_train as before\n",
    "model.fit(X_train_list, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = model.predict(X_test_list)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4dc04382584b0d985ad55d961d0bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with custom threshold of 0.7: 0.9805825242718447\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        74\n",
      "           1       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.98       103\n",
      "   macro avg       0.99      0.97      0.98       103\n",
      "weighted avg       0.98      0.98      0.98       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### accuracy with 0.6 as threshold\n",
    "\n",
    "# Get predicted probabilities for the positive class\n",
    "y_pred_probs = model.predict_proba(X_test_list)[:, 1]\n",
    "\n",
    "# Apply threshold to determine predicted labels\n",
    "threshold = 0.7\n",
    "y_pred_custom_threshold = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "custom_accuracy = accuracy_score(y_test, y_pred_custom_threshold)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy with custom threshold of {threshold}: {custom_accuracy}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_custom_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f127afbaaf6470e9f6a1df860e4975b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c100f5e0cda74cdfbc65d5d4d509439b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9902912621359223\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        74\n",
      "           1       1.00      0.97      0.98        29\n",
      "\n",
      "    accuracy                           0.99       103\n",
      "   macro avg       0.99      0.98      0.99       103\n",
      "weighted avg       0.99      0.99      0.99       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the pipeline with Gradient Boosting Classifier\n",
    "model_gb = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_gb.fit(X_train_list, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred_gb = model_gb.predict(X_test_list)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4894d33f91cd488aa8c64f1584abdda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with custom threshold of 0.6: 0.9805825242718447\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        74\n",
      "           1       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.98       103\n",
      "   macro avg       0.99      0.97      0.98       103\n",
      "weighted avg       0.98      0.98      0.98       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities for the positive class\n",
    "y_pred_probs = model_gb.predict_proba(X_test_list)[:, 1]\n",
    "\n",
    "# Apply threshold to determine predicted labels\n",
    "threshold = 0.6\n",
    "y_pred_custom_threshold = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "custom_accuracy = accuracy_score(y_test, y_pred_custom_threshold)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy with custom threshold of {threshold}: {custom_accuracy}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_custom_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tates\\AppData\\Local\\Temp\\ipykernel_21972\\248090769.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Data</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Table Number</th>\n",
       "      <th>IsQuestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To code, please use a checkmark () for each s...</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT \\nTRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOME \\nTIMES</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I felt miserable or unhappy.</td>\n",
       "      <td>C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Cell Data  \\\n",
       "0  To code, please use a checkmark () for each s...   \n",
       "1                                         NOT \\nTRUE   \n",
       "2                                       SOME \\nTIMES   \n",
       "3                                               TRUE   \n",
       "4                    1. I felt miserable or unhappy.   \n",
       "\n",
       "                                            Filename  Table Number  IsQuestion  \n",
       "0  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "1  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "2  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "3  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           0  \n",
       "4  C:\\Users\\tates\\Downloads\\pdf-questionnaire-ext...             1           1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = r'C:\\Users\\tates\\Classwork\\open-source\\harmony\\processed'\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)  # Load the CSV file\n",
    "        \n",
    "        # Check if 'IsQuestion' column exists\n",
    "        if 'IsQuestion' in df.columns:\n",
    "            # Convert NaN values to 0 and then the column to integers\n",
    "            df['IsQuestion'] = df['IsQuestion'].fillna(0).astype(int)\n",
    "            dfs.append(df)  # Append the dataframe to the list\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# If you want to save the combined dataframe to a new CSV file\n",
    "# combined_df.to_csv('combined_csv.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the combined dataframe\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'].fillna(''), combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Ensure X_train and X_test are lists\n",
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class SentenceTransformerEmbedder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to fit\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Convert texts to embeddings\n",
    "        embeddings = self.model.encode(X, show_progress_bar=True)\n",
    "        return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4511457998624f849b27fc1bf96f6d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee91374d5fe4e748e41284d7b5782d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9902912621359223\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        74\n",
      "           1       1.00      0.97      0.98        29\n",
      "\n",
      "    accuracy                           0.99       103\n",
      "   macro avg       0.99      0.98      0.99       103\n",
      "weighted avg       0.99      0.99      0.99       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the pipeline with XGBClassifier\n",
    "model_xgb = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_xgb.fit(X_train_list, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred_xgb = model_xgb.predict(X_test_list)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_test_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_pred_xgb\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "X_test_list[y_pred_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/json_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(model_xgb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 31/31 [00:34<00:00,  1.11s/it]\n",
      "Batches: 100%|██████████| 2/2 [00:06<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9827586206896551\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       1.00      0.97      0.98        33\n",
      "\n",
      "    accuracy                           0.98        58\n",
      "   macro avg       0.98      0.98      0.98        58\n",
      "weighted avg       0.98      0.98      0.98        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 28/28 [00:31<00:00,  1.12s/it]\n",
      "Batches: 100%|██████████| 5/5 [00:11<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        78\n",
      "           1       1.00      1.00      1.00        67\n",
      "\n",
      "    accuracy                           1.00       145\n",
      "   macro avg       1.00      1.00      1.00       145\n",
      "weighted avg       1.00      1.00      1.00       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 30/30 [00:31<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 3/3 [00:11<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        51\n",
      "           1       0.91      0.98      0.95        44\n",
      "\n",
      "    accuracy                           0.95        95\n",
      "   macro avg       0.95      0.95      0.95        95\n",
      "weighted avg       0.95      0.95      0.95        95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 28/28 [00:31<00:00,  1.13s/it]\n",
      "Batches: 100%|██████████| 5/5 [00:11<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9699248120300752\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97        80\n",
      "           1       0.95      0.98      0.96        53\n",
      "\n",
      "    accuracy                           0.97       133\n",
      "   macro avg       0.97      0.97      0.97       133\n",
      "weighted avg       0.97      0.97      0.97       133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 27/27 [00:41<00:00,  1.53s/it]\n",
      "Batches: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9315789473684211\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       157\n",
      "           1       0.73      0.97      0.83        33\n",
      "\n",
      "    accuracy                           0.93       190\n",
      "   macro avg       0.86      0.95      0.89       190\n",
      "weighted avg       0.95      0.93      0.94       190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:08<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7692307692307693\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        12\n",
      "           1       1.00      0.57      0.73        14\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.83      0.79      0.76        26\n",
      "weighted avg       0.85      0.77      0.76        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 21/21 [00:32<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 12/12 [00:10<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958005249343832\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       277\n",
      "           1       0.98      0.87      0.92       104\n",
      "\n",
      "    accuracy                           0.96       381\n",
      "   macro avg       0.96      0.93      0.95       381\n",
      "weighted avg       0.96      0.96      0.96       381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9369809742450548"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "filepaths = combined_df['Filename'].unique()\n",
    "random.shuffle(filepaths)\n",
    "\n",
    "def split_data(filepaths, n_validation, all_files):\n",
    "    validation_files = filepaths[:n_validation]\n",
    "    training_files = set(all_files) - set(validation_files)\n",
    "    return validation_files, training_files\n",
    "\n",
    "n_validation_files = 2\n",
    "\n",
    "all_files = filepaths\n",
    "scores = []\n",
    "while len(filepaths) > 0:\n",
    "    validation_files, training_files = split_data(filepaths, n_validation_files, all_files)\n",
    "    \n",
    "    validation_data = combined_df[combined_df['Filename'].isin(validation_files)]\n",
    "\n",
    "    training_data = combined_df[combined_df['Filename'].isin(training_files)]\n",
    "    \n",
    "    model_xgb = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ])\n",
    "    model_xgb.fit(training_data['Cell Data'].tolist(), training_data['IsQuestion'])\n",
    "\n",
    "    y_pred_xgb = model_xgb.predict(validation_data['Cell Data'].tolist())\n",
    "    score = accuracy_score(validation_data['IsQuestion'], y_pred_xgb)\n",
    "    scores.append(score)\n",
    "    print(\"Accuracy:\", score)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(validation_data['IsQuestion'], y_pred_xgb))\n",
    "    filepaths = filepaths[n_validation_files:]\n",
    "np.average(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000_mfqchildselfreportshort.csv\n",
      "001_patienthealthquestionnaire.csv\n",
      "002_bhrcsparentreportysi.csv\n",
      "003_bhrcsselfreporteddeliberartese.csv\n",
      "004_newyorklongitudinalstudybythom.csv\n",
      "005_beckdepressioninventorybdi.csv\n",
      "006_apadsm5severitymeasurefordepre.csv\n",
      "007_bhrcsselfreportedscared.csv\n",
      "008_gad7anxietyupdated0.csv\n",
      "009_validationoftheportugueseversi.csv\n",
      "010_patienthealthquestionnairephq9.csv\n",
      "011_bhrcsparentreportsocialaptitud.csv\n",
      "012_hrcw2protocolopsicoconfmenor18.csv\n",
      "013_hrcw2protocolopsicoadultos.csv\n",
      "014_testedeansiedadegad7dranadimme.csv\n",
      "015_hrcw1dom.csv\n",
      "016_hrcw2protocolodomiciliarmenor1.csv\n",
      "017_validationoftheportugueseversi.csv\n",
      "018_scaredformparentandchildversio.csv\n",
      "019_bhrcsparentreportsocialcohesio.csv\n",
      "020_hrcw2protocolopsicomenor18.csv\n",
      "021_sdqenglishukpt417single.csv\n",
      "022_cesd.csv\n",
      "023_hrcw1psico.csv\n",
      "024_bhrcsselfreportedmfq.csv\n",
      "025_phq9questionnaire.csv\n",
      "026_sf36.csv\n",
      "027_hrcw2protocolodomiciliaradulto.csv\n",
      "028_mfqchildselfreportlong.csv\n",
      "029_bhrcsselfreportedsdq.csv\n",
      "030_bhrcsselfreportedwarwickedinbr.csv\n",
      "031_ghq12.csv\n",
      "033_malaise24item.csv\n",
      "034_bhrcsparentreportsocialcohesio.csv\n",
      "035_machadopaulacristinamoraisapen.csv\n",
      "036_adhdquestionnaireasrs111.csv\n",
      "037_hrcw0dom.csv\n",
      "038_mcs7youngpersononlinecawiquest.csv\n",
      "039_selfmeasuresforlonelinessandin.csv\n",
      "040_hrcw0psico.csv\n",
      "041_rcadschildreported818.csv\n",
      "042_bhrcsparentreportabcl.csv\n",
      "043_nanopdfcomscoresheetfortheorig.csv\n",
      "044_bhrcsparentreportcbcl.csv\n",
      "045_mr0510201tb.csv\n",
      "046_borderlinepersonalityscreener.csv\n",
      "047_bhrcsparentreportsdqadult.csv\n",
      "048_hrcw2protocolopsicoconfadultos.csv\n",
      "049_hrcbscreen.csv\n",
      "050_british_births.csv\n",
      "051_scanned_old_doc.csv\n",
      "052_phq9iddate0803.csv\n",
      "052_social_attitudes.csv\n",
      "053_neighbourhood.csv\n",
      "054_class_teacher.csv\n",
      "055_beta_retirement.csv\n",
      "056_race_related.csv\n",
      "057_ndshs2016.csv\n",
      "058_new_zealand.csv\n",
      "059_foreign_affairs.csv\n",
      "060_pgsi.csv\n",
      "061_k10.csv\n",
      "062_eoin_no_numbers.csv\n",
      "063_nz_election.csv\n",
      "064_hrcw1psicoconf.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>IsQuestion</th>\n",
       "      <th>Filename</th>\n",
       "      <th>comment</th>\n",
       "      <th>Note</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>000_mfqchildselfreportshort.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Child Self-Report</td>\n",
       "      <td>0</td>\n",
       "      <td>000_mfqchildselfreportshort.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>000_mfqchildselfreportshort.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>000_mfqchildselfreportshort.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>000_mfqchildselfreportshort.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Text  IsQuestion                         Filename comment   \n",
       "0                NaN           0  000_mfqchildselfreportshort.csv     NaN  \\\n",
       "1  Child Self-Report           0  000_mfqchildselfreportshort.csv     NaN   \n",
       "2                NaN           0  000_mfqchildselfreportshort.csv     NaN   \n",
       "3                NaN           0  000_mfqchildselfreportshort.csv     NaN   \n",
       "4                NaN           0  000_mfqchildselfreportshort.csv     NaN   \n",
       "\n",
       "  Note Unnamed: 2  \n",
       "0  NaN        NaN  \n",
       "1  NaN        NaN  \n",
       "2  NaN        NaN  \n",
       "3  NaN        NaN  \n",
       "4  NaN        NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = r'C:\\Users\\tates\\Classwork\\open-source\\harmony\\text_processed'\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "filenames = []  # List to store filenames\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "        # print(filename)  # Print the filename\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)  # Load the CSV file\n",
    "        # Add a 'Filename' column filled with the current filename\n",
    "        df['Filename'] = filename\n",
    "        # Check if 'IsQuestion' column exists\n",
    "        if 'IsQuestion' in df.columns:\n",
    "            print(filename)\n",
    "            # Convert NaN values to 0 and then the column to integers\n",
    "            df['IsQuestion'] = df['IsQuestion'].fillna(0).astype(int)\n",
    "            dfs.append(df)  # Append the dataframe to the list\n",
    "            filenames.append(filename)  # Append filename to the list\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# If you want to save the combined dataframe to a new CSV file\n",
    "# combined_df.to_csv('combined_csv.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the combined dataframe\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text           91967\n",
       "IsQuestion         0\n",
       "Filename           0\n",
       "comment       175777\n",
       "Note          176405\n",
       "Unnamed: 2    176383\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176429, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsQuestion\n",
       "0    165065\n",
       "1     11364\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"IsQuestion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['Text'], combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Ensure X_train and X_test are lists\n",
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = [str(text) for text in X_train_list]\n",
    "X_test_list = [str(text) for text in X_test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4963/4963 [31:31<00:00,  2.62it/s] \n",
      "Batches: 100%|██████████| 552/552 [03:13<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.948931587598481\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     16550\n",
      "           1       0.66      0.36      0.46      1093\n",
      "\n",
      "    accuracy                           0.95     17643\n",
      "   macro avg       0.81      0.67      0.72     17643\n",
      "weighted avg       0.94      0.95      0.94     17643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the pipeline with XGBClassifier\n",
    "model_xgb = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_xgb.fit(X_train_list, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred_xgb = model_xgb.predict(X_test_list)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"Text\"] = combined_df[\"Text\"].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Text  IsQuestion\n",
      "0                                      Child Self-Report           0\n",
      "1         MOOD AND FEELINGS QUESTIONNAIRE: Short Version           0\n",
      "2      This form is about how you might have been fee...           0\n",
      "3      For each question, please check () how you ha...           0\n",
      "4      If a sentence was not true about you, check NO...           0\n",
      "...                                                  ...         ...\n",
      "52355  Q34. Por favor, marque com um X no número do q...           0\n",
      "52356  (   ) Quadro 1 (   ) Quadro 2 (   ) Quadro 4 (...           0\n",
      "52357  Q35. Por favor, marque com um X no número do q...           0\n",
      "52358  (   ) Quadro 1 (   ) Quadro 2 (   ) Quadro 4 (...           0\n",
      "52359  ÁLCOOL CIGARRO E SUBSTÂNCIAS RELAÇÕES SEXUAIS ...           0\n",
      "\n",
      "[52360 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = combined_df[['Text', 'IsQuestion']]\n",
    "\n",
    "# Function to combine rows of 'Text' column\n",
    "def combine_text_rows(df):\n",
    "    combined_text = []\n",
    "    combined_other = []\n",
    "    current_text = ''\n",
    "    current_other = ''\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Text'] != '':\n",
    "            current_text += str(row['Text']) + ' '\n",
    "            current_other = row['IsQuestion']\n",
    "        else:\n",
    "            if current_text != '':\n",
    "                combined_text.append(current_text.strip())\n",
    "                combined_other.append(current_other)\n",
    "                current_text = ''\n",
    "    \n",
    "    # If there's remaining text after the loop ends\n",
    "    if current_text != '':\n",
    "        combined_text.append(current_text.strip())\n",
    "        combined_other.append(current_other)\n",
    "    \n",
    "    combined_df = pd.DataFrame({'Text': combined_text, 'IsQuestion': combined_other})\n",
    "    return combined_df\n",
    "\n",
    "# Call the function to combine rows\n",
    "processed_df = combine_text_rows(df)\n",
    "print(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv(\"processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52360, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsQuestion\n",
       "0    44889\n",
       "1     7471\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df[\"IsQuestion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_df['Text'], processed_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Ensure X_train and X_test are lists\n",
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1473/1473 [24:12<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 164/164 [02:20<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8842627960275019\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      4490\n",
      "           1       0.71      0.32      0.44       746\n",
      "\n",
      "    accuracy                           0.88      5236\n",
      "   macro avg       0.80      0.65      0.69      5236\n",
      "weighted avg       0.87      0.88      0.86      5236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the pipeline with XGBClassifier\n",
    "model_xgb = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_xgb.fit(X_train_list, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred_xgb = model_xgb.predict(X_test_list)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class SentenceTransformerEmbedder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to fit\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Convert texts to embeddings\n",
    "        embeddings = self.model.encode(X, show_progress_bar=True)\n",
    "        return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners = [('rf_model', RandomForestClassifier(criterion = 'entropy', max_depth = 10, max_features = 'sqrt',\n",
    "                                                     max_leaf_nodes = 8, min_samples_leaf = 5, min_samples_split = 2,\n",
    "                                                     n_estimators = 50, random_state = 10)),\n",
    "                 ('KNN_model', KNeighborsClassifier(n_neighbors = 17, metric = 'euclidean')),\n",
    "                 ('NB_model', GaussianNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1473/1473 [22:06<00:00,  1.11it/s]\n",
      "Batches: 100%|██████████| 164/164 [02:23<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8687929717341482\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      4490\n",
      "           1       0.53      0.76      0.62       746\n",
      "\n",
      "    accuracy                           0.87      5236\n",
      "   macro avg       0.74      0.82      0.77      5236\n",
      "weighted avg       0.90      0.87      0.88      5236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stack_model = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier',StackingClassifier(estimators = base_learners, final_estimator = GaussianNB())),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "stack_model.fit(X_train_list, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred_stack = stack_model.predict(X_test_list)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/stack_model_without_preprocessing.pkl', 'wb') as f:\n",
    "    pickle.dump(stack_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for undersampling\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming combined_df is your DataFrame\n",
    "# Separate the classes\n",
    "class_0 = processed_df[processed_df['IsQuestion'] == 0]\n",
    "class_1 = processed_df[processed_df['IsQuestion'] == 1]\n",
    "\n",
    "# Sample 30% of class 0 without replacement\n",
    "class_0_sampled = class_0.sample(frac=0.3, random_state=42)\n",
    "\n",
    "# Combine the sampled class 0 data with all of class 1 data\n",
    "combined_sampled_df = pd.concat([class_0_sampled, class_1])\n",
    "\n",
    "# Now you split the combined_sampled_df into training and testing sets\n",
    "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(\n",
    "    combined_sampled_df['Text'],\n",
    "    combined_sampled_df['IsQuestion'],\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ensure X_train and X_test are lists if needed\n",
    "X_train_list_us = X_train_us.tolist()\n",
    "X_test_list_us = X_test_us.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/us_data.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_sampled_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 589/589 [10:37<00:00,  1.08s/it] \n",
      "Batches: 100%|██████████| 66/66 [01:16<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7970391595033429\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83      1342\n",
      "           1       0.68      0.83      0.75       752\n",
      "\n",
      "    accuracy                           0.80      2094\n",
      "   macro avg       0.78      0.80      0.79      2094\n",
      "weighted avg       0.81      0.80      0.80      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stack_model = Pipeline([\n",
    "    ('embedder', SentenceTransformerEmbedder()),\n",
    "    ('classifier',StackingClassifier(estimators = base_learners, final_estimator = GaussianNB())),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "stack_model.fit(X_train_list_us, y_train_us)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred_stack_us = stack_model.predict(X_test_list_us)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test_us, y_pred_stack_us))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_us, y_pred_stack_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/stack_model_with_undersampling.pkl', 'wb') as f:\n",
    "    pickle.dump(stack_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = list(class_weight.compute_class_weight(class_weight= 'balanced',\n",
    "                                             classes = np.unique(combined_sampled_df['IsQuestion']),\n",
    "                                             y = combined_sampled_df['IsQuestion']))\n",
    "\n",
    "#df['Product'].value_counts()\n",
    "\n",
    "class_weights.sort()\n",
    "\n",
    "class_weights\n",
    "\n",
    "weightsus={}\n",
    "\n",
    "\n",
    "for index, weight in enumerate(class_weights) :\n",
    "    weightsus[index]=weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7773817479765353, 1: 1.4012849685450408}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = list(class_weight.compute_class_weight(class_weight= 'balanced',\n",
    "                                             classes = np.unique(processed_df['IsQuestion']),\n",
    "                                             y = processed_df['IsQuestion']))\n",
    "\n",
    "#df['Product'].value_counts()\n",
    "\n",
    "class_weights.sort()\n",
    "\n",
    "class_weights\n",
    "\n",
    "weights={}\n",
    "\n",
    "\n",
    "for index, weight in enumerate(class_weights) :\n",
    "    weights[index]=weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68303b91e35433e89d643340b23a536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e5f830a72246f487913ee36c562696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,362,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">918,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │     \u001b[38;5;34m2,362,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m918,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,297,409</span> (12.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,297,409\u001b[0m (12.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,297,409</span> (12.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,297,409\u001b[0m (12.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 77ms/step - accuracy: 0.7390 - loss: 0.4833 - val_accuracy: 0.8094 - val_loss: 0.3703\n",
      "Epoch 2/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.8145 - loss: 0.3574 - val_accuracy: 0.8291 - val_loss: 0.3547\n",
      "Epoch 3/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.8325 - loss: 0.3197 - val_accuracy: 0.8612 - val_loss: 0.3008\n",
      "Epoch 4/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.8525 - loss: 0.2941 - val_accuracy: 0.8592 - val_loss: 0.2981\n",
      "Epoch 5/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.8576 - loss: 0.2751 - val_accuracy: 0.8562 - val_loss: 0.3126\n",
      "Epoch 6/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.8692 - loss: 0.2525 - val_accuracy: 0.8757 - val_loss: 0.2681\n",
      "Epoch 7/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8690 - loss: 0.2525 - val_accuracy: 0.8686 - val_loss: 0.2968\n",
      "Epoch 8/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8698 - loss: 0.2363 - val_accuracy: 0.8736 - val_loss: 0.2948\n",
      "Epoch 9/25\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.8842 - loss: 0.2181 - val_accuracy: 0.8690 - val_loss: 0.2779\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming 'combined_df' is your DataFrame containing the data\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 384  # Adjusted to match the Sentence Transformer model's embedding size\n",
    "\n",
    "# Load the pretrained Sentence Transformer model\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Function to preprocess text data using Sentence Transformer\n",
    "def get_embeddings(sentences):\n",
    "    return sentence_model.encode(sentences, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'], combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert X_train and X_test to lists to ensure proper indexing\n",
    "# X_train_list = X_train.tolist()\n",
    "# X_test_list = X_test.tolist()\n",
    "\n",
    "# Preprocess the text data to get embeddings\n",
    "train_embeddings = get_embeddings(X_train_list)\n",
    "test_embeddings = get_embeddings(X_test_list)\n",
    "\n",
    "# Reshape the embeddings to add a \"sequence\" dimension\n",
    "train_embeddings = np.expand_dims(train_embeddings, axis=1)\n",
    "test_embeddings = np.expand_dims(test_embeddings, axis=1)\n",
    "\n",
    "# LSTM Model Architecture\n",
    "model = tf.keras.Sequential([\n",
    "    # Input shape is now (1, embedding_dim) since we're treating each embedding as a single timestep\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim, return_sequences=True), input_shape=(1, embedding_dim)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False)),  # Example dimension reduction\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Example additional dense layer\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Overview of the model\n",
    "model.summary()\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 256\n",
    "epochs = 25\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_embeddings, np.array(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_embeddings, np.array(y_test)),\n",
    "    class_weight=weights,  # Ensure 'weights' is defined as per your original code\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5236, 2094]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m y_pred_labels \u001b[38;5;241m=\u001b[39m (y_pred \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[1;32m----> 8\u001b[0m classification\u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification)\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2604\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2470\u001b[0m     {\n\u001b[0;32m   2471\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2495\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2496\u001b[0m ):\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \n\u001b[0;32m   2499\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2604\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2607\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5236, 2094]"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_embeddings)\n",
    "\n",
    "threshold = 0.75\n",
    "y_pred_labels = (y_pred > threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "classification= classification_report(y_test, y_pred_labels)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/lstm_without_undersampling.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 1, 384], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Then by loading the model back\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/lstm_without_undersampling.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Check its architecture\u001b[39;00m\n\u001b[0;32m      6\u001b[0m new_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:870\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 1, 384], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "\n",
    "# Then by loading the model back\n",
    "import tensorflow as tf\n",
    "new_model = tf.keras.models.load_model('models/lstm_without_undersampling.h5')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34abe686fed4c80b5baf137755d3030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3187ae432c3045c895d2ae8adf87faea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirection  (None, 1, 768)            2362368   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 256)               918528    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3297409 (12.58 MB)\n",
      "Trainable params: 3297409 (12.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "74/74 [==============================] - 44s 219ms/step - loss: 0.4534 - accuracy: 0.7787 - val_loss: 0.4202 - val_accuracy: 0.7966\n",
      "Epoch 2/25\n",
      "74/74 [==============================] - 13s 179ms/step - loss: 0.3759 - accuracy: 0.8217 - val_loss: 0.3747 - val_accuracy: 0.8281\n",
      "Epoch 3/25\n",
      "74/74 [==============================] - 12s 159ms/step - loss: 0.3447 - accuracy: 0.8389 - val_loss: 0.3501 - val_accuracy: 0.8434\n",
      "Epoch 4/25\n",
      "74/74 [==============================] - 11s 146ms/step - loss: 0.3178 - accuracy: 0.8570 - val_loss: 0.3576 - val_accuracy: 0.8453\n",
      "Epoch 5/25\n",
      "74/74 [==============================] - 9s 127ms/step - loss: 0.2984 - accuracy: 0.8676 - val_loss: 0.3422 - val_accuracy: 0.8567\n",
      "Epoch 6/25\n",
      "74/74 [==============================] - 9s 116ms/step - loss: 0.2823 - accuracy: 0.8745 - val_loss: 0.3164 - val_accuracy: 0.8658\n",
      "Epoch 7/25\n",
      "74/74 [==============================] - 8s 109ms/step - loss: 0.2647 - accuracy: 0.8844 - val_loss: 0.3269 - val_accuracy: 0.8596\n",
      "Epoch 8/25\n",
      "74/74 [==============================] - 9s 124ms/step - loss: 0.2558 - accuracy: 0.8875 - val_loss: 0.3095 - val_accuracy: 0.8749\n",
      "Epoch 9/25\n",
      "74/74 [==============================] - 9s 115ms/step - loss: 0.2361 - accuracy: 0.8960 - val_loss: 0.3264 - val_accuracy: 0.8615\n",
      "Epoch 10/25\n",
      "74/74 [==============================] - 9s 117ms/step - loss: 0.2245 - accuracy: 0.8984 - val_loss: 0.3325 - val_accuracy: 0.8663\n",
      "Epoch 11/25\n",
      "74/74 [==============================] - 8s 114ms/step - loss: 0.2182 - accuracy: 0.9034 - val_loss: 0.3252 - val_accuracy: 0.8701\n"
     ]
    }
   ],
   "source": [
    "#LSTM with undersampling\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming 'combined_df' is your DataFrame containing the data\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 384  # Adjusted to match the Sentence Transformer model's embedding size\n",
    "\n",
    "# Load the pretrained Sentence Transformer model\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Function to preprocess text data using Sentence Transformer\n",
    "def get_embeddings(sentences):\n",
    "    return sentence_model.encode(sentences, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(combined_df['Cell Data'], combined_df['IsQuestion'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert X_train and X_test to lists to ensure proper indexing\n",
    "# X_train_list = X_train.tolist()\n",
    "# X_test_list = X_test.tolist()\n",
    "\n",
    "# Preprocess the text data to get embeddings\n",
    "train_embeddings = get_embeddings(X_train_list_us)\n",
    "test_embeddings = get_embeddings(X_test_list_us)\n",
    "\n",
    "# Reshape the embeddings to add a \"sequence\" dimension\n",
    "train_embeddings = np.expand_dims(train_embeddings, axis=1)\n",
    "test_embeddings = np.expand_dims(test_embeddings, axis=1)\n",
    "\n",
    "# LSTM Model Architecture\n",
    "model = tf.keras.Sequential([\n",
    "    # Input shape is now (1, embedding_dim) since we're treating each embedding as a single timestep\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim, return_sequences=True), input_shape=(1, embedding_dim)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False)),  # Example dimension reduction\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Example additional dense layer\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Overview of the model\n",
    "model.summary()\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 256\n",
    "epochs = 25\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_embeddings, np.array(y_train_us),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_embeddings, np.array(y_test_us)),\n",
    "    class_weight=weightsus,  # Ensure 'weights' is defined as per your original code\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 5s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1342\n",
      "           1       0.82      0.78      0.80       752\n",
      "\n",
      "    accuracy                           0.86      2094\n",
      "   macro avg       0.85      0.84      0.85      2094\n",
      "weighted avg       0.86      0.86      0.86      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_embeddings)\n",
    "\n",
    "threshold = 0.75\n",
    "y_pred_labels = (y_pred > threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "classification= classification_report(y_test_us, y_pred_labels)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\tates\\Classwork\\open-source\\harmony\\models\\lstm_with_undersampling.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.4.1.post1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: C:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"models/lstm_with_undersampling.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Load the pretrained Sentence Transformer model\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Function to preprocess text data using Sentence Transformer\n",
    "def get_embeddings(sentences):\n",
    "    return sentence_model.encode(sentences, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "def txt_to_df(lines):\n",
    "    # Remove newline characters from each line\n",
    "    cleaned_lines = [line.strip() for line in lines]\n",
    "\n",
    "    df = pd.DataFrame(cleaned_lines, columns=['Text'])\n",
    "\n",
    "    print(f\"Converted text to dataframe\")\n",
    "    return df\n",
    "def combine_text_rows(df):\n",
    "    combined_text = []\n",
    "    combined_other = []\n",
    "    current_text = ''\n",
    "    df[\"Text\"] = df[\"Text\"].fillna('')\n",
    "    for _, row in df.iterrows():\n",
    "        if row['Text'] != '':\n",
    "            current_text += str(row['Text']) + ' '\n",
    "            \n",
    "        else:\n",
    "            if current_text != '':\n",
    "                combined_text.append(current_text.strip())\n",
    "                current_text = ''\n",
    "    \n",
    "    # If there's remaining text after the loop ends\n",
    "    if current_text != '':\n",
    "        combined_text.append(current_text.strip())\n",
    "    \n",
    "    combined_df = pd.DataFrame({'Text': combined_text})\n",
    "    return combined_df\n",
    "def preprocess_json(json_data):\n",
    "    data = json_data\n",
    "\n",
    "    # Prepare data for DataFrame\n",
    "    df_data = []\n",
    "\n",
    "    # Iterate over each table in the JSON file\n",
    "    for table_number, table_info in enumerate(data['pageTables'], start=1):\n",
    "        table_data = table_info['tables']\n",
    "\n",
    "        # Iterate over each cell in the table\n",
    "        for row in table_data:\n",
    "            for cell in row:\n",
    "                df_data.append({\n",
    "                    'Cell Data': cell,\n",
    "                    'Table Number': table_number\n",
    "                })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df_data)\n",
    "    return df\n",
    "\n",
    "def find_questions(text, json_data, lstm=False):\n",
    "    \n",
    "    final_questions = []\n",
    "    json_df = preprocess_json(json_data)\n",
    "    # Load the model from the pickle file\n",
    "    with open('models/json_xgb.pkl', 'rb') as file:\n",
    "        json_model = pickle.load(file)\n",
    "    y_pred_json = json_model.predict(json_df['Cell Data'].tolist())\n",
    "    y_pred_series = pd.Series(y_pred_json)\n",
    "    questions = json_df[y_pred_series == 1]\n",
    "    questions['Cell Data'] = questions['Cell Data'].str.strip()\n",
    "    print(questions)\n",
    "    final_questions = questions['Cell Data'].tolist()\n",
    "\n",
    "    ################text##########################\n",
    "    df = txt_to_df(text)\n",
    "    df = combine_text_rows(df)\n",
    "    \n",
    "    #regex to find questions\n",
    "    pattern = r'(^.*(?:who|what|when|where|why|how|\\?)$)|(^\\d+\\.\\sI.*\\.$)'\n",
    "    df['Text'] = df['Text'].str.strip()\n",
    "    mask_df = df['Text'].str.contains(pattern, regex=True)\n",
    "    valid_questions = df[mask_df]\n",
    "    final_questions.extend(valid_questions['Text'].tolist())\n",
    "    df = df[~mask_df]\n",
    "    print(df,\"df\")\n",
    "\n",
    "    if lstm:\n",
    "        model_file_path = r'models/lstm_with_undersampling.keras'\n",
    "        model = load_model(model_file_path)\n",
    "\n",
    "        predict_embeddings = get_embeddings(df['Text'].tolist())\n",
    "        predict_embeddings = np.expand_dims(predict_embeddings, axis=1)\n",
    "        y_pred = model.predict(predict_embeddings)\n",
    "\n",
    "        mask = (y_pred > 0.75).astype(int)\n",
    "        mask = mask.flatten()\n",
    "\n",
    "        # Create a boolean Series with the same index as df\n",
    "        y_pred_series = pd.Series(mask, index=df.index)\n",
    "\n",
    "        # Filter the DataFrame using boolean indexing\n",
    "        questions = df[y_pred_series == 1]\n",
    "        print(questions)\n",
    "        final_questions.extend(questions['Text'].tolist())\n",
    "    else:\n",
    "        with open('models/stack_model_without_undersampling.pkl', 'rb') as file:\n",
    "            text_model = pickle.load(file)\n",
    "        y_pred_text = text_model.predict(df['Text'].tolist())\n",
    "        y_pred_series = pd.Series(y_pred_text)\n",
    "        questions = df[y_pred_series == 1]\n",
    "        final_questions.extend(questions['Text'].tolist())\n",
    "    return list(set(final_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8719e7b9d2048aa8097f9ab9186a7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtates\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mClasswork\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mopen-source\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpdf-questionnaire-extraction-main (1)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpdf-questionnaire-extraction-main\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpreprocessed_tables\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m000_mfqchildselfreportshort.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m         json_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m----> 5\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfind_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(ans)\n",
      "Cell \u001b[1;32mIn[1], line 75\u001b[0m, in \u001b[0;36mfind_questions\u001b[1;34m(text, json_data, lstm)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/json_xgb.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     74\u001b[0m     json_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m---> 75\u001b[0m y_pred_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCell Data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m y_pred_series \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(y_pred_json)\n\u001b[0;32m     77\u001b[0m questions \u001b[38;5;241m=\u001b[39m json_df[y_pred_series \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\sklearn\\pipeline.py:602\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 602\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tates\\Classwork\\open-source\\harmony\\harmony\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m, in \u001b[0;36mSentenceTransformerEmbedder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Convert texts to embeddings\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode(X, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(embeddings)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "with open(r\"C:\\Users\\tates\\Classwork\\open-source\\pdf-questionnaire-extraction-main (1)\\pdf-questionnaire-extraction-main\\data\\preprocessed_text\\000_mfqchildselfreportshort.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.readlines()\n",
    "with open(r\"C:\\Users\\tates\\Classwork\\open-source\\pdf-questionnaire-extraction-main (1)\\pdf-questionnaire-extraction-main\\data\\preprocessed_tables\\000_mfqchildselfreportshort.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "ans = find_questions(text, json_data, lstm =True)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'I worry about things', 'Never/Sometimes/Often/Always']\n",
      "['2', 'I feel sad or empty', 'Never/Sometimes/Often/Always']\n",
      "['3', 'When I have a problem, I get a funny feeling in my stomach', 'Never/Sometimes/Often/Always']\n",
      "['4', 'I worry when I think I have done poorly at something', 'Never/Sometimes/Often/Always']\n",
      "['5', 'I would feel afraid of being on my own at home', 'Never/Sometimes/Often/Always']\n",
      "['6', 'Nothing is much fun anymore', 'Never/Sometimes/Often/Always']\n",
      "['7', 'I feel scared when I have to take a test', 'Never/Sometimes/Often/Always']\n",
      "['8', 'I feel worried when I think someone is angry with me', 'Never/Sometimes/Often/Always']\n",
      "['9', 'I worry about being away from my parent', 'Never/Sometimes/Often/Always']\n",
      "['10', 'I am bothered by bad or silly thoughts or pictures in my mind', 'Never/Sometimes/Often/Always']\n",
      "['11', 'I have trouble sleeping', 'Never/Sometimes/Often/Always']\n",
      "['12', 'I worry that I will do badly at my school work', 'Never/Sometimes/Often/Always']\n",
      "['13', 'I worry that something awful will happen to someone in my family', 'Never/Sometimes/Often/Always']\n",
      "['14', 'I suddenly feel as if I can’t breathe when there is no reason for this', 'Never/Sometimes/Often/Always']\n",
      "['15', 'I have problems with my appetite', 'Never/Sometimes/Often/Always']\n",
      "['16', 'I have to keep checking that I have done things right (like the switch is off, or the door is locked)', 'Never/Sometimes/Often/Always']\n",
      "['17', 'I feel scared if I have to sleep on my own', 'Never/Sometimes/Often/Always']\n",
      "['18', 'I have trouble going to school in the mornings because I feel nervous or afraid', 'Never/Sometimes/Often/Always']\n",
      "['19', 'I have no energy for things', 'Never/Sometimes/Often/Always']\n",
      "['20', 'I worry I might look foolish', 'Never/Sometimes/Often/Always']\n",
      "['21', 'I am tired a lot', 'Never/Sometimes/Often/Always']\n",
      "['22', 'I worry that bad things will happen to me', 'Never/Sometimes/Often/Always']\n",
      "['23', 'I can’t seem to get bad or silly thoughts out of my head', 'Never/Sometimes/Often/Always']\n",
      "['24', 'When I have a problem, my heart beats really fast', 'Never/Sometimes/Often/Always']\n",
      "['25', 'I cannot think clearly', 'Never/Sometimes/Often/Always']\n",
      "['26', 'I suddenly start to tremble or shake when there is no reason for this', 'Never/Sometimes/Often/Always']\n",
      "['27', 'I worry that something bad will happen to me', 'Never/Sometimes/Often/Always']\n",
      "['28', 'When I have a problem, I feel shaky', 'Never/Sometimes/Often/Always']\n",
      "['29', 'I feel worthless', 'Never/Sometimes/Often/Always']\n",
      "['30', 'I worry about making mistakes', 'Never/Sometimes/Often/Always']\n",
      "['31', 'I have to think of special thoughts (like numbers or words) to stop bad things from happening', 'Never/Sometimes/Often/Always']\n",
      "['32', 'I worry what other people think of me', 'Never/Sometimes/Often/Always']\n",
      "['33', 'I am afraid of being in crowded places (like shopping centers, the movies, buses, busy playgrounds)', 'Never/Sometimes/Often/Always']\n",
      "['34', 'All of a sudden I feel really scared for no reason at all', 'Never/Sometimes/Often/Always']\n",
      "['35', 'I worry about what is going to happen', 'Never/Sometimes/Often/Always']\n",
      "['36', 'I suddenly become dizzy or faint when there is no reason for this', 'Never/Sometimes/Often/Always']\n",
      "['37', 'I think about death', 'Never/Sometimes/Often/Always']\n",
      "['38', 'I feel afraid if I have to talk in front of my class', 'Never/Sometimes/Often/Always']\n",
      "['39', 'My heart suddenly starts to beat too quickly for no reason', 'Never/Sometimes/Often/Always']\n",
      "['40', 'I feel like I don’t want to move', 'Never/Sometimes/Often/Always']\n",
      "['41', 'I worry that I will suddenly get a scared feeling when there is nothing to be afraid of', 'Never/Sometimes/Often/Always']\n",
      "['42', 'I have to do some things over and over again (like washing my hands, cleaning or putting things in a certain order)', 'Never/Sometimes/Often/Always']\n",
      "['43', 'I feel afraid that I will make a fool of myself in front of people', 'Never/Sometimes/Often/Always']\n",
      "['44', 'I have to do some things in just the right way to stop bad things from happening', 'Never/Sometimes/Often/Always']\n",
      "['45', 'I worry when I go to bed at night', 'Never/Sometimes/Often/Always']\n",
      "['46', 'I would feel scared if I had to stay away from home overnight', 'Never/Sometimes/Often/Always']\n",
      "['47', 'I feel restless', 'Never/Sometimes/Often/Always']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "ground_truths = []\n",
    "with open(r\"C:\\Users\\tates\\Classwork\\open-source\\pdf-questionnaire-extraction-main (1)\\pdf-questionnaire-extraction-main\\data\\annotations\\041_rcadschildreported818.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for l in f:\n",
    "            l = re.sub(r'\\n', '', l)\n",
    "            c = l.split(\"\\t\")\n",
    "            print(c)\n",
    "            ground_truths.append(re.sub(r'\\W', '', c[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
